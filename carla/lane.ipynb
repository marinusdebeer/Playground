{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "# Connect to CARLA server\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(5.0)\n",
    "# Get the world and blueprint library\n",
    "world = client.get_world()\n",
    "blueprint_library = world.get_blueprint_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn a vehicle\n",
    "vehicle_bp = blueprint_library.filter('model3')[0]\n",
    "spawn_point = carla.Transform(carla.Location(x=0, y=137, z=0.1), carla.Rotation(pitch=0.0, yaw=180.0, roll=0.0))\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "\n",
    "# Attach a camera sensor to the vehicle\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute(\"image_size_x\", f\"{IM_WIDTH}\")\n",
    "camera_bp.set_attribute(\"image_size_y\", f\"{IM_HEIGHT}\")\n",
    "camera_transform = carla.Transform(carla.Location(x=2.0, z=1.5), carla.Rotation(pitch=-15.0))\n",
    "camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)\n",
    "\n",
    "seg_camera_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n",
    "seg_camera_bp.set_attribute(\"image_size_x\", f\"{IM_WIDTH}\")\n",
    "seg_camera_bp.set_attribute(\"image_size_y\", f\"{IM_HEIGHT}\")\n",
    "seg_camera_transform = carla.Transform(carla.Location(x=2.0, z=1.5), carla.Rotation(pitch=-15.0))\n",
    "\n",
    "# Spawn the camera and attach to the vehicle\n",
    "seg_camera = world.spawn_actor(seg_camera_bp, seg_camera_transform, attach_to=vehicle)\n",
    "\n",
    "def process_image(image):\n",
    "    try:\n",
    "        i = np.array(image.raw_data)\n",
    "        #print(i.shape)\n",
    "        i2 = i.reshape((IM_HEIGHT, IM_WIDTH, 4))\n",
    "        i3 = i2[:, :, :3]\n",
    "        gray = cv2.cvtColor(i3, cv2.COLOR_BGR2GRAY)\n",
    "        return gray\n",
    "    except Exception as e:\n",
    "        print(\"Error in process_image:\", str(e))\n",
    "        return None\n",
    "\n",
    "def detect_lanes(gray):\n",
    "    try:\n",
    "        display_image = gray.copy()\n",
    "        # mask_white = cv2.inRange(gray, 175, 255)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "        # Edge Detection\n",
    "        edges = cv2.Canny(blurred, 70, 70)\n",
    "        height, width = edges.shape\n",
    "        roi_vertices = [\n",
    "            (0, height),\n",
    "            (0, height * 0.3), # left (x, y)\n",
    "            (width, height * 0.3), # right (x, y)\n",
    "            (width, height)\n",
    "        ]\n",
    "\n",
    "        mask = np.zeros_like(edges)\n",
    "        cv2.fillPoly(mask, [np.array(roi_vertices, dtype=np.int32)], 255)\n",
    "        roi = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "        lines = cv2.HoughLinesP(roi, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=100)\n",
    "        black_image = np.zeros((height, width, 3), np.uint8)\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                    cv2.line(black_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "                    cv2.line(display_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "        # Original Image Display\n",
    "        # cv2.imshow('Edges', edges)\n",
    "        # cv2.imshow('ROI', roi)\n",
    "        # cv2.imshow(\"Mask\", mask)\n",
    "        # cv2.imshow(\"mask white\", mask_white)\n",
    "        # cv2.imshow(\"black\", black_image)\n",
    "        cv2.imshow(\"Original\", display_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        # Compute lane center based on lines\n",
    "        if lines is not None and len(lines) > 1:\n",
    "            left_lane, right_lane = lines[0][0], lines[1][0]\n",
    "            lane_center = ((left_lane[0] + right_lane[0]) / 2, (left_lane[1] + right_lane[1]) / 2)\n",
    "            # print(f\"left_lane: {left_lane}, right_lane: {right_lane}, lane_center: {lane_center}\")\n",
    "        else:\n",
    "            lane_center = (width / 2, height)\n",
    "        \n",
    "        return lane_center\n",
    "    except Exception as e:\n",
    "        print(\"Error in detect_lanes:\", str(e))\n",
    "    return (400, 300)\n",
    "\n",
    "def process_semantic_image(image):\n",
    "    # Convert the raw data to a numpy array\n",
    "    semantic_array = np.array(image.raw_data).reshape((IM_HEIGHT, IM_WIDTH, 4))\n",
    "    \n",
    "    # Extract only the R channel (which contains the class labels)\n",
    "    labels = semantic_array[:, :, 2]\n",
    "\n",
    "    # Define a colormap to represent different classes (e.g., red for vehicles, green for pedestrians, etc.)\n",
    "    # Adjust this colormap as per your needs.\n",
    "    colormap = {\n",
    "        # 0: [0, 0, 0],        # None\n",
    "        1: [70, 70, 70],    # road\n",
    "        # 2: [190, 153, 153], # sidewalks\n",
    "        # 3: [250, 170, 160], # building\n",
    "        # 4: [220, 20, 60],   # not sure\n",
    "        # 5: [153, 153, 153], # not sure\n",
    "        # 6: [157, 234, 50],  # light poles\n",
    "        # 7: [128, 64, 128],  # traffic lights\n",
    "        # 8: [244, 35, 232],  # TrafficSign\n",
    "        # 10: [0, 0, 142],    # not sure\n",
    "        # 11: [244, 35, 232],    # sky\n",
    "        # 14: [244, 35, 232],    # cars\n",
    "        # 20: [244, 35, 232],    # Dynamic\n",
    "        # 22: [244, 35, 232],    # Dynamic\n",
    "        # Add other classes as needed\n",
    "    }\n",
    "\n",
    "    # Convert labels to RGB based on the colormap\n",
    "    semantic_rgb = np.zeros((IM_HEIGHT, IM_WIDTH, 3))\n",
    "    for key, value in colormap.items():\n",
    "        semantic_rgb[np.where(labels == key)] = value\n",
    "\n",
    "    return semantic_rgb.astype(np.uint8)\n",
    "# Define a function for steering control\n",
    "def control_vehicle(lane_center):\n",
    "    try:\n",
    "        # _, width, _ = world.get_settings().screen_resolution\n",
    "        car_center = IM_WIDTH / 2.0\n",
    "\n",
    "        deviation = lane_center[0] - car_center\n",
    "        kp = 0.0007\n",
    "        steering = -kp * deviation\n",
    "        # print(steering)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0.5, steer=steering))\n",
    "    except Exception as e:\n",
    "        print(\"Error in control_vehicle:\", str(e))\n",
    "\n",
    "def callback(image):\n",
    "    semantic_processed = process_semantic_image(image)\n",
    "    # cv2.imshow(\"Semantic Processed\", semantic_processed)\n",
    "\n",
    "    # processed_image = process_image(image)\n",
    "    processed_image = cv2.cvtColor(semantic_processed, cv2.COLOR_BGR2GRAY)\n",
    "    # cv2.imshow(\"Grayscale\", processed_image)\n",
    "\n",
    "    lane_center = detect_lanes(processed_image)\n",
    "    # print(\"Callback called. Lane center:\", lane_center)\n",
    "    control_vehicle(lane_center)\n",
    "\n",
    "def semantic_callback(image):\n",
    "    # processed_image = process_image(image)\n",
    "    processed_image = process_semantic_image(image)\n",
    "    cv2.imshow(\"Semantic Segmentation\", processed_image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Listen to camera images, detect lanes, and control the vehicle\n",
    "# camera.listen(callback)\n",
    "seg_camera.listen(callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0  Y: 137\n",
      "X: 20  Y: 137\n",
      "X: 40  Y: 138\n",
      "X: 60  Y: 138\n",
      "X: 80  Y: 134\n",
      "X: 96  Y: 121\n",
      "X: 105  Y: 103\n",
      "X: 106  Y: 82\n",
      "X: 106  Y: 62\n",
      "X: 106  Y: 42\n",
      "X: 106  Y: 22\n",
      "X: 106  Y: 2\n",
      "X: 106  Y: -18\n",
      "X: 104  Y: -38\n",
      "X: 92  Y: -55\n",
      "X: 73  Y: -64\n",
      "X: 53  Y: -64\n",
      "X: 33  Y: -64\n",
      "X: 13  Y: -64\n",
      "X: -7  Y: -65\n",
      "X: -27  Y: -65\n",
      "X: -46  Y: -57\n",
      "X: -49  Y: -37\n",
      "X: -49  Y: -17\n",
      "X: -48  Y: 4\n",
      "X: -39  Y: 22\n",
      "X: -19  Y: 25\n",
      "X: 1  Y: 25\n",
      "X: 21  Y: 25\n",
      "X: 41  Y: 25\n",
      "X: 61  Y: 25\n",
      "X: 81  Y: 25\n",
      "X: 102  Y: 21\n",
      "X: 110  Y: 2\n",
      "X: 110  Y: -18\n",
      "X: 107  Y: -39\n",
      "X: 94  Y: -58\n",
      "X: 74  Y: -67\n",
      "X: 53  Y: -68\n",
      "X: 33  Y: -68\n",
      "X: 13  Y: -68\n",
      "X: -7  Y: -68\n",
      "X: -27  Y: -68\n",
      "X: -47  Y: -68\n",
      "X: -67  Y: -69\n",
      "X: -89  Y: -64\n",
      "X: -106  Y: -49\n",
      "X: -113  Y: -28\n",
      "X: -114  Y: -8\n",
      "X: -114  Y: 12\n",
      "X: -114  Y: 32\n",
      "X: -114  Y: 52\n",
      "X: -115  Y: 72\n",
      "X: -113  Y: 94\n",
      "X: -105  Y: 114\n",
      "X: -91  Y: 131\n",
      "X: -71  Y: 140\n",
      "X: -50  Y: 140\n",
      "X: -30  Y: 141\n",
      "X: -10  Y: 141\n",
      "X: 10  Y: 141\n",
      "X: 30  Y: 141\n",
      "X: 50  Y: 141\n",
      "X: 71  Y: 141\n",
      "X: 92  Y: 132\n",
      "X: 105  Y: 114\n",
      "X: 109  Y: 92\n",
      "X: 109  Y: 72\n",
      "X: 110  Y: 52\n",
      "X: 110  Y: 32\n",
      "X: 110  Y: 12\n",
      "X: 110  Y: -8\n",
      "X: 110  Y: -29\n",
      "X: 102  Y: -49\n",
      "X: 84  Y: -64\n",
      "X: 63  Y: -68\n",
      "X: 43  Y: -68\n",
      "X: 23  Y: -68\n",
      "X: 3  Y: -68\n",
      "X: -17  Y: -68\n",
      "X: -37  Y: -68\n",
      "X: -57  Y: -69\n",
      "X: -78  Y: -68\n",
      "X: -99  Y: -58\n",
      "X: -110  Y: -39\n",
      "X: -114  Y: -17\n",
      "X: -114  Y: 3\n",
      "X: -114  Y: 23\n",
      "X: -114  Y: 43\n",
      "X: -114  Y: 63\n",
      "X: -114  Y: 83\n",
      "X: -110  Y: 104\n",
      "X: -99  Y: 123\n",
      "X: -81  Y: 136\n",
      "X: -60  Y: 140\n",
      "X: -40  Y: 140\n",
      "X: -20  Y: 141\n",
      "X: 0  Y: 141\n",
      "X: 20  Y: 141\n",
      "X: 40  Y: 141\n",
      "X: 60  Y: 141\n",
      "X: 82  Y: 138\n",
      "X: 99  Y: 123\n",
      "X: 108  Y: 103\n",
      "X: 109  Y: 82\n",
      "X: 109  Y: 62\n",
      "X: 110  Y: 42\n",
      "X: 110  Y: 22\n",
      "X: 110  Y: 2\n",
      "X: 110  Y: -18\n",
      "X: 107  Y: -40\n",
      "X: 94  Y: -58\n",
      "X: 73  Y: -67\n",
      "X: 52  Y: -68\n",
      "X: 32  Y: -68\n",
      "X: 12  Y: -68\n",
      "X: -8  Y: -68\n",
      "X: -28  Y: -68\n",
      "X: -47  Y: -68\n",
      "X: -67  Y: -69\n"
     ]
    }
   ],
   "source": [
    "# Start from a known location on the track\n",
    "start_location = carla.Location(x=0, y=137, z=0.1)  # Change to your desired starting location\n",
    "waypoint_api = map.get_waypoint(start_location)\n",
    "\n",
    "waypoint_list = []\n",
    "next_waypoint = waypoint_api\n",
    "distance = 20.0  # distance between consecutive waypoints\n",
    "num_waypoints = 120  # Number of waypoints to generate, adjust as needed\n",
    "\n",
    "for _ in range(num_waypoints):\n",
    "    # Append to the list\n",
    "    waypoint_list.append(next_waypoint)\n",
    "\n",
    "    # Print x and y coordinates\n",
    "    print(\"X:\", round(next_waypoint.transform.location.x), \" Y:\", round(next_waypoint.transform.location.y))\n",
    "    # world.debug.draw_point(next_waypoint.transform.location, size=0.1, color=carla.Color(255,0,0), life_time=5)\n",
    "    world.debug.draw_line(vehicle.get_transform().location, next_waypoint.transform.location, thickness=0.05, color=carla.Color(0,0,255), life_time=5)\n",
    "\n",
    "    # Get the next waypoint\n",
    "    next_waypoint = next_waypoint.next(distance)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each waypoint you want to visualize:\n",
    "world.debug.draw_point(carla.Location(x=0, y=137, z=0.1), size=0.1, color=carla.Color(255,0,0), life_time=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DebugHelper' object has no attribute 'clear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mar\\OneDrive\\Desktop\\Development\\Playground\\carla\\lane.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mar/OneDrive/Desktop/Development/Playground/carla/lane.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m world\u001b[39m.\u001b[39;49mdebug\u001b[39m.\u001b[39;49mclear()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DebugHelper' object has no attribute 'clear'"
     ]
    }
   ],
   "source": [
    "world.debug.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
