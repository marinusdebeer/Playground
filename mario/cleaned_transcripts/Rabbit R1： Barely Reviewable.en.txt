(upbeat music)
- So, this is the Rabbit R1.
And it&amp;#39;s another AI in a box,
and it&amp;#39;s a sign of the times.
So this thing here,
it has a lot in common
with the Humane Ai Pin,
for better or for worse.
But it&amp;#39;s also supposed to
have two specific things
that are supposed to
set it apart from that.
Supposed to, anyway.
And we have to talk about it.
(letters clicking)
(tense music)
So, stop me if this sounds
familiar at any point,
but check this out.
This is a virtual assistant in a box.
But it&amp;#39;s a different box.
This one is not wearable.
It&amp;#39;s a thing you have
to carry around with you
in your pocket, like a smartphone.
I&amp;#39;d say it&amp;#39;s about the size
of a stack of Post-its, maybe.
But it&amp;#39;s this lightweight plastic cube,
designed by Teenage Engineering.
And boy, do people love some
Teenage Engineering right now.
And it&amp;#39;s super...
I mean, you can tell exactly
what it is from a mile away.
This thing is very recognizable.
The thing has one button
on the right side.
That&amp;#39;s the one you press and
hold to ask it questions.
And then instead of a projector,
it actually does have
a built-in screen here.
And instead of built-in cellular,
it has a SIM card tray right alongside
that USB Type-C port for charging.
I&amp;#39;d say it does seem to send basically
every single request to
the Cloud, but I will say,
it does feel significantly quicker
to answer questions
than the Humane Ai Pin.
Now, that is a very,
very low bar to clear,
but it&amp;#39;s consistent, it&amp;#39;s
consistently quicker.
How far away is the moon?
- [AI Voice] The average distance
between Earth and the Moon
is approximately 384,400 kilometers.
- You can connect
headphones via Bluetooth,
or turn the built-in speaker
all the way up, like I have.
But it also shows you
the text of your answer
on the screen, right underneath
this bouncing rabbit,
and the time in the battery.
Matter of fact, it basically always shows
this bouncing rabbit all the time.
It&amp;#39;s how you know it&amp;#39;s awake.
You hit that button
once to put it to sleep.
Or it would do that automatically
after a few seconds.
Then hit the button again to wake it up.
Boom, just the rabbit
waiting for you there.
And then to get to settings,
there&amp;#39;s no button to press for that.
There&amp;#39;s no gesture on
the screen or anything.
You just shake it like an Etch A Sketch.
And as long as you do that,
then from there you can scroll up and down
with this scroll wheel,
and select with the button.
That&amp;#39;s how you get around the UI.
So, the other two things it has
are the scroll wheel
and a swiveling camera.
So the scroll wheel for
navigating around the UI
instead of the screen is...
I&amp;#39;ll get to why it&amp;#39;s odd in a second.
But then of course, the AI
assistant is multimodal,
and so you can use vision
to answer questions
about what it sees.
So we&amp;#39;ve seen this before.
With this one, you
double-tap to swivel it open,
and then press and hold to ask.
I don&amp;#39;t know. What type of plant is this?
- [AI Voice] Taking a look now.
The plant in the image appears
to be a Monstera deliciosa,
also known as a Swiss cheese plant.
This is a type of tropical
climbing evergreen plant
native to southern Mexico
and parts of Central America.
The large glossy green
leaves with distinctive-
- As a reviewer testing this thing,
I just feel like that DJ
Khaled clip after a while,
where I&amp;#39;m just pointing at stuff,
like, &amp;quot;Okay, what is this?
And what is this?&amp;quot;
- And what is this?
- [Speaker] Those are
pickled banana peppers.
- [DJ Khaled] And what is this?
- [Speaker] Berries and seeds.
- [DJ Khaled] And perhaps what is this?
- [Speaker] Water.
- But I&amp;#39;ve also, I&amp;#39;ve just
pointed it at my computer screen
with a really long email on it,
and asked it for a summary,
and it just reads an instantly
and gives me a summary of it.
It&amp;#39;s done that with articles too.
I think that&amp;#39;s pretty cool.
But yeah, it&amp;#39;s just a...
It&amp;#39;s an AI in a box.
It&amp;#39;s best at just answering questions.
(text clicking)
(soft music)
So yeah, this thing is
also bad at a lot of stuff.
And this list is gonna
sound pretty familiar.
Somehow, the battery life is
just as bad as the Humane Pin.
It has a thousand million
power battery inside
and it&amp;#39;s brutally bad.
Like it&amp;#39;s already bad enough
when you&amp;#39;re carrying around
a whole nother device
alongside your smartphone,
but when this one can sit in
front of you doing nothing,
and the battery just visibly is draining
and dies in like four hours...
Then you have to charge
it multiple times per day,
and it&amp;#39;s still dead when
you wake up in the morning.
Like, it&amp;#39;s just exhausting.
Also, it took 45 minutes
to charge this tiny battery
from zero to a hundred.
And it&amp;#39;s also just straight up missing
a ton of what I would
consider just basic features.
Like it can&amp;#39;t set
alarms, can&amp;#39;t set timers,
it can&amp;#39;t record videos,
can&amp;#39;t record photos,
can&amp;#39;t send emails, there&amp;#39;s
no calendar built in.
There&amp;#39;s just a lot of
things that I would want
an assistant to do...
Not here.
And of course, being an AI assistant,
it also does still hallucinate,
and confidently answer questions wrong.
Like my baseline of asking a question
that I know the answer to,
and then getting the wrong
answer happens all the time.
Which is one of the
downfalls of this category.
So this device was designed
by Teenage Engineering.
And they&amp;#39;re really leaning into that.
Like that&amp;#39;s why...
I mean, it&amp;#39;s this bright
orange, it is really quirky,
friendly looking device, I
would say, intentionally.
But yeah, they really love
their analog controls.
And this scroll wheel
here doesn&amp;#39;t surprise me,
but it&amp;#39;s actually really
frustrating to use.
First of all, it protrudes
out the back a little bit,
as you can see.
Which looks kinda cool.
But that means if it was really sensitive,
that it would actually scroll
if you just put it down
on a table or something.
So they&amp;#39;ve dialed down the
sensitivity of the scroll wheel,
so it&amp;#39;s actually super slow.
Like there&amp;#39;s a surprising
amount of scroll motion
required to go down one
line in the settings.
And then there&amp;#39;s no haptic
feedback here as you&amp;#39;re scrolling
to help you feel it out.
So fine, okay, you can get used to that.
You use the button to select...
But then you&amp;#39;ve also noticed,
there&amp;#39;s no back button
anywhere on this device.
So to go back up a level,
you have to scroll all
the way back up to the top
every single time.
That also gets annoying.
And then to change brightness or volume,
you actually need two hands.
So you just go into brightness to select,
and you hold the button with one hand,
and then scroll the scroll wheel
with the other hand to adjust brightness.
Which, yeah, you can&amp;#39;t
do it with one hand.
It works, so you can learn
it, and you can say, you know,
it&amp;#39;s this quirky UI it&amp;#39;s got going on.
But I feel like a lot of
these problems would be solved
if this was a touch screen.
So what if I told you
this is a touch screen,
and they just don&amp;#39;t really let you use it
for almost anything?
Like moving through these
menus would be easier
if I could just tap
what I wanted to, right?
Going back after a long
scroll would be easier
if I could just flip scroll
back to the top of a list,
and hit back.
But you can&amp;#39;t.
The only thing you can
use the touchscreen for
is basically typing on the
keyboard in terminal mode.
So with terminal enabled,
you can turn it sideways,
a keyboard pops up, and
you can type your questions
and get text answers.
Which is great.
And you can move between
letters with the scroll wheel.
It&amp;#39;s kind of a neat feature, I guess.
But why can&amp;#39;t we use the touch
screen for anything else?
Is it just them trying
not to look too much
like a smartphone?
Maybe.
Probably.
(text clicking)
(tense music)
So, okay, what&amp;#39;s the point?
Why does this thing exist?
If it&amp;#39;s so similar to the other one
that was also so bad,
what are we doing here?
And really, there&amp;#39;s two things
that I think they&amp;#39;re
hoping will be the things
that set it apart from the other one.
That should, in the words of
their co-founder, Jesse...
- But I don&amp;#39;t think MKBHD will say
this is the worst device
he ever reviewed so far.
(people laughing)
- Which, low bar, but okay.
Those two things are the price tag,
and the large action model.
So the Humane Pin was so
easy for everyone to dunk on
because it costs as much as a phone.
It was $700 with a $24
a month subscription
to not turn into a brick.
It&amp;#39;s just insane.
So, this one right here costs
$200 and no subscription.
So, you know, okay, that
hits a little different.
But also, you can tell it&amp;#39;s $200.
First of all, you will
need a separate SIM card
to get it to work on cellular.
So while there is no
subscription fee for Rabbit
to keep the device working,
that is still a fee you&amp;#39;re
gonna pay every month
to get data outside of wifi.
But then, okay, the unboxing experience
is extremely minimal.
It comes in a single cardboard box
with a cassette tape
looking plastic container,
that doubles as a stand,
but there&amp;#39;s literally nothing else.
No charging brick, no
USB-C cable, no stickers,
no paper instruction
manual, nothing at all.
And then the R1 itself is made of plastic.
Not to say that it&amp;#39;s not built well.
You know, there&amp;#39;s no flexing or creaking
or anything like that.
But it&amp;#39;s definitely plastic.
The camera, very basic.
The speaker, very cheap.
You know, it&amp;#39;s a low end
MediaTek chip inside.
The same one that&amp;#39;s in
the Moto G8 Power Lite,
which is like $150 phone.
Hardly any battery, as we learned.
And no fancy fast charging
or wireless charging.
And it comes in one color,
really bright orange.
Like this ridiculously
saturated bright orange.
I&amp;#39;m not even joking,
the color you&amp;#39;re seeing
in this YouTube video on your screen,
it&amp;#39;s gonna be the best I can do
with my own color correction.
But it&amp;#39;s legitimately hard to photograph.
Like the phone camera doesn&amp;#39;t really
turn saturation up high enough
to really represent it
accurately in real life.
It&amp;#39;s the brightest orange thing
you&amp;#39;ve ever seen in your
life, I guarantee it.
Now, if you want something
a little more low key
than the neon orange,
channel sponsor dbrand actually
does have you covered here.
I&amp;#39;ve got this black camo looking one here,
and now the orange bits that show through
are kind of like more accent
pieces, which is pretty dope.
But fun fact, dbrand also
collaborated with Rabbit
ahead of the release to make sure
screen protectors for this thing
were also available on launch day.
So, that includes mine.
If you wanna check it out,
screen protectors or skins for the R1,
you can hit up the link below.
But yes, speaking of the screen,
this is a 2.9 inch diagonal TFT screen,
with no auto brightness.
So, yeah, I think you get the idea.
(letters clicking)
(soft music)
So you know how the
Humane Ai Pin had no apps?
Well, this thing also has no apps.
But the other thing that they&amp;#39;re hoping
will separate it from the other stuff,
is what they&amp;#39;re calling
a large action model.
So you know, large language
models are just the words,
the language that we use.
So it&amp;#39;s an AI that can
take our natural language,
and process it, and turn
it into words in return.
And that&amp;#39;s how we interact with it.
So a large action model is
supposed to take our words,
and then process it, and
turn it into actions.
That&amp;#39;s the theory.
So it&amp;#39;s basically going to
be able to use apps for you
like a human would,
based on what you tell it to do.
Now, importantly, this
isn&amp;#39;t the same as an API,
where you know, a company
might work with the others
to have some sort of a
plug into their services
so that they work together.
Because an API can be a
little too restrictive,
or not give all the features,
or just not quite...
I mean, there&amp;#39;s lots of good reasons
why they don&amp;#39;t wanna rely on an API.
So what this is supposed to be doing,
is just going in and using
the app, just like a human,
essentially with like
a mouse and a keyboard.
Think of it as like a virtual agent.
Honestly, I think it&amp;#39;s a really cool idea.
I think it&amp;#39;s a really, really cool idea.
You know, large language
models have been trained,
with all their data,
to talk back to us just like humans would,
and some are very convincing.
So a large action model, in theory,
should be able to use
these apps and services
just like a human would.
From Spotify to Twitter,
to your banking app,
to whatever else.
It&amp;#39;s already good enough at
recognizing major UI elements
like a play button or a buy
button and things like that.
So with enough training
data, could get really good.
With enough training data,
could get really good.
But the thing is,
they don&amp;#39;t have a ton
of training data yet.
So as of right now, they have
made four apps available.
Four.
They have this online portal
called the Rabbit Hole,
where you can log into
and enable all of them.
Spotify, Uber, DoorDash and Midjourney.
So the Rabbit can talk to these four apps,
and has a UI on the screen for doing so
in the exact way that we&amp;#39;re theorizing.
So it&amp;#39;ll play Spotify songs.
Like I can ask it for a song,
and it&amp;#39;ll try to play the right one,
and it&amp;#39;ll show you any info
you need on the touch screen
to confirm or refine the
actions you&amp;#39;re taking.
But even now, they kinda work.
Like, I&amp;#39;ve already had issues with it
playing the wrong song.
I&amp;#39;ve also seen other
people already have issues
with the DoorDash app
getting things wrong,
which is even more frustrating.
I can&amp;#39;t imagine how
frustrating the Uber app
messing up would be.
It definitely seems like it
needs more training data.
And that&amp;#39;s just for
these four starting apps.
Now, Rabbit says they have
800 different apps trained already,
but they just haven&amp;#39;t
built a UI for it yet,
so it&amp;#39;s not available on the Rabbit yet.
And so that&amp;#39;s still in the works.
Now they&amp;#39;ve also theoretically
started working on something
called a generative UI,
where essentially it can recognize
what type of app it is,
and then build a UI for it
so Rabbit doesn&amp;#39;t have to...
But that&amp;#39;s also still theoretical,
and also on the roadmap
and still in the works.
And then if there&amp;#39;s another app or service
that you want your
Rabbit to be able to do,
like something for work,
or something super niche
that you&amp;#39;ve invented,
they&amp;#39;ve talked about
something called &amp;quot;Teach Mode&amp;quot;.
Which is basically having
the Rabbit watch you
do what you want it to do
on your mouse and keyboard,
and then it learns from what you did,
and can then repeat your
actions later, which is sick.
Unfortunately, you can probably already
see where this is going,
Teach Mode is also not
available as of right now.
This is something they&amp;#39;re still working on
vetting and finishing.
And so that&amp;#39;s just later
this year, also in the works.
So as of right now,
this device has none of that stuff,
just the four kind of half working apps
that we went over at the beginning.
What are we doing here?
(letters clicking)
(soft music)
Okay, I&amp;#39;m gonna try not
to turn this into a rant,
but I feel like we need
to acknowledge at least,
that a lot of these tech companies
are developing tech kinda backwards.
Like they&amp;#39;re delivering
such unfinished products,
that it actually makes them
nearly impossible to review.
Like, it feels like it used to just be,
make the thing, and then put it on sale.
Now it&amp;#39;s like put it on sale,
and then deliver the half-baked thing,
and then iterate and make it better,
and hopefully with enough
updates, then it&amp;#39;s ready,
and it&amp;#39;s what we promised
way back when we first started selling it.
And then this whole period
in the middle is a mess.
And it&amp;#39;s across all kinds
of product categories too.
We&amp;#39;ve seen this with gaming.
Like huge studios are delivering
half-baked games saying,
&amp;quot;Oh, you know, it&amp;#39;s an alpha version.
There will be updates.&amp;quot;
But meanwhile, it&amp;#39;s a full price AAA game
that&amp;#39;s just gotten an unacceptable number
of bugs and issues.
It&amp;#39;s also happening with cars.
And vehicles getting announced,
and then delivering with
like a half-finished state,
where you just don&amp;#39;t get
a lot of the features
that you paid for.
And they&amp;#39;re eventually coming soon,
with a software update.
You know, smartphones, obviously,
we&amp;#39;ve been seeing this for years,
but it does seem like now more than ever,
there&amp;#39;s at least one feature,
one major feature of
every smartphone launch
that gets announced,
but that&amp;#39;s not coming
until later in the year.
And now these AI based
products are at like the apex
of this horrible trend where,
the thing that you get at the beginning
is like borderline nonfunctional
compared to all the promises
and all the features
and all the things that it&amp;#39;s
supposed to maybe someday be.
But you still pay full
price at the beginning,
which is what makes it so crazy.
And that sucks not only obviously
for the people buying it at
full price at the beginning,
but also for reviewing
these things in general.
Like, how do you assess a product
where the version of what&amp;#39;s
promised in like three years,
what it could be is amazing,
but the version that&amp;#39;s being
delivered now is dog water.
Like, how do you connect those dots?
Do you even connect those dots?
Are you supposed to give them
the benefit of the doubt?
I don&amp;#39;t know. What are we even doing here?
I mean, I guess on one hand,
it is good that tech products,
these things can get better
over time and improve,
and the thing you buy
can be better tomorrow.
That&amp;#39;s all great.
That didn&amp;#39;t used to be true,
and that&amp;#39;s beautiful and everything.
But on the other hand,
it&amp;#39;s just, the other side of that coin,
is some very unfinished
products being delivered,
and I just feel like it&amp;#39;s gonna get worse
before it gets better.
(letters clicking)
(tense music)
So, let me just say,
I am personally very excited
by the idea of a super
personalized AI assistant
that can do everything that
a human assistant could.
That&amp;#39;s my dream. I want that to happen.
And I&amp;#39;m interested that
these different companies
are approaching it from different angles.
And hopefully, we&amp;#39;ll get there eventually.
But this is also so clearly going to take
a lot of time and effort
and technical development,
and also a lot of data.
Like, I&amp;#39;ve said this already
in the Humane review,
I&amp;#39;m pretty sure, which is a
good assistant needs to know
everything about you, whether
it&amp;#39;s human or virtual.
Like it needs to know your preferences,
and your location,
and what you&amp;#39;re doing,
and what you like to do.
And every single little thing.
It&amp;#39;s so much data.
So as for the Rabbit...
I think that&amp;#39;s why they focused
on getting the price so low.
Like, this stuff is all a tough sell,
because you&amp;#39;re taking a gamble
on what the product could be someday.
But for the Pin, you have to
drop $700, and $24 every month,
on the chance that it
might someday get there.
Like that&amp;#39;s a lot of money.
But for this cute little thing, 200 bucks.
Feels like a much easier
investment to make.
A much easier pill to swallow,
to just take a gamble on it.
And on the off chance it
turns out to be awesome
in a couple of years, it&amp;#39;ll
feel like it&amp;#39;s worth it.
You know, on the chance
that some of those 800 apps
are super useful.
Or you know, even though you
already have a smartphone,
maybe the Teach Mode lets it do something
with a single button press
that you could never dream of before,
then it could be totally worth it.
The whole situation reminds me kind of...
If you look back at the beginning
of when Tesla started shipping cars
with all the autopilot stuff.
They were selling cars,
and they got popular for other reasons.
It was a good electric
car with good range,
and a good charging network.
And then people started
sort of beta testing
this autopilot stuff,
and Tesla starts collecting
millions of miles and hours of data,
from how it works in the real world.
And so all of that data
helped their systems learn,
and get the head start that they need,
on trying to make the
best autopilot software.
So the Rabbit, I&amp;#39;m sure,
would like to use their price advantage,
and get as many of them out
into the real world as possible,
into people&amp;#39;s hands,
so they can start beta testing,
and having it trained and getting good
at a variety of tasks.
But the Rabbit&amp;#39;s problem is,
it doesn&amp;#39;t have like the other reason
why people would get it anyway today.
So it&amp;#39;s like a kind of
chicken and egg problem.
So if you want my advice,
you&amp;#39;ve heard it before.
Buy the product based on what it is today,
and not what it&amp;#39;s promised
to be in the future.
And with this category, that&amp;#39;s
like the hardest thing to do,
the hardest thing to keep in mind.
&amp;#39;Cause the promise is so big.
But that&amp;#39;s still my advice.
And I guess we still also have yet to see
what big companies like Google and Apple
are gonna try to do in this
space, probably this year.
So, with all of that, we&amp;#39;ll see.
Thanks for watching.
Catch you in the next one.
Peace.
(mellow music fades)