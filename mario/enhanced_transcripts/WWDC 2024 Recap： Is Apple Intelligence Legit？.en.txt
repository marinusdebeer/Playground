(upbeat music)

We just wrapped up what might be one of the biggest Apple WWDC keynotes ever, possibly due to the current state of the world and the high expectations surrounding tech companies in 2024, especially in regard to AI. Interestingly, Apple placed AI at the back half of their presentation; they didn't mention it at all in the first hour. Then in the second hour, they essentially said, "Okay, we actually have a lot of AI features to share," and then presented them all at once. They even branded it as "Apple Intelligence."

I watched and live-tweeted the entire two-hour keynote, so you don’t have to. Here are my thoughts on the key announcements, organized in the same order that Apple presented them.

Starting with VisionOS, we're already on VisionOS 2.0 less than six months after the Vision Pro was first announced. There are some solid new features, but I hesitate to call this a 2.0 worthy update; it feels more like a 1.2 update. However, there is a new wrist turn gesture that allows you to quickly check the time and battery percentage, enabling you to jump straight into the control center without having to glance up at the ceiling like before. It reminds me of the Oculus Quest—it's a nice improvement.

Additionally, there are immersive media features, such as the ability to browse old photos and use advanced machine learning to turn them into spatial photos. If it works well, that could be interesting. There are also new tools for creating spatial and immersive videos on cameras other than the iPhone, but they can only be viewed on the Vision Pro, so their practical value is uncertain.

This year, Mac mirroring will enjoy a significant resolution boost due to foveated rendering on the Mac. This change frees up a lot of resources, allowing for up to double the resolution. It means more room for windows and activities, which is fantastic. Overall, while the 2.0 update isn’t groundbreaking, it does introduce some appealing features, including new environments and the ability to rearrange your home screen—something you couldn’t do before.

Speaking of home screen customization, iOS has now received one of its most significant updates in a long time. If you’re an Android user, feel free to take a quick break for the next few minutes. Yes, Android has had these features for a while, but now it's the iPhone's turn to shine. You can finally place icons wherever you want on the iOS 18 home screen grid. It was amusing to see it receive applause during the keynote, as if it were a groundbreaking new feature. Nevertheless, Apple fans have waited a long time for this.

They haven't stopped there. Numerous other customization features have been added, including a new theme engine that lets you change the color of every icon and widget on your home screen to match your wallpaper—a simple update that Android users have enjoyed for years. Before this, every iPhone home screen looked largely the same, but now users have the freedom to customize it, which can lead to some questionable designs. 

The ability to create unappealing home screens is apparent on Twitter, with many looking quite chaotic. Some apps support this theme well, while others end up with icons that appear just tinted, causing legibility issues. So, while you can create aesthetic home screens, it’s just as easy to create a confusing mess. 

I tried to gauge if I liked this more or less than Google's Material You on Pixel devices. Technically, Apple's solution is better because it allows changes to all icons at once. So, you don’t have to deal with certain apps standing out awkwardly. 

Apple has also redesigned the Control Center to be fully customizable across multiple pages, providing more shortcuts and options. Now you can finally replace the flashlight and camera icons on the home screen without jailbreaking your device. 

There are also hidden apps you can place in your app drawer, making it easier to conceal apps like Tinder. You can now schedule text messages in iMessage—finally! Apple is starting to add some fun features. Other updates include message formatting, satellite messaging, and a redesigned Photos app. There's even a game mode that minimizes background activity and reduces Bluetooth latency. Plus, the Mail app is getting automatic categorization.

There are numerous enhancements. I’ll likely create a detailed video focused solely on iOS 18 to cover all these updates since there are plenty of minor features not included in the keynote. So be sure to subscribe to catch that.

Moving on to AirPods, they received minor updates like voice isolation during phone calls, spatial audio for gaming, and the ability to respond to prompts with nods or shakes—similar to Sony headphones. I appreciate that you can now control them without using your voice. 

Apple TV has a new feature that allows you to swipe down on the remote at any point during a show to see a real-time list of actors and character names, as well as any song playing at that moment. There’s also a feature that boosts dialogue audio, making it easier to hear over the music.

In watchOS, there's a new training mode that helps balance your workout trends and evaluates your effort relative to your potential. 

As for iPadOS, this was Apple's big chance to convince everyone why the new iPad—now with the M4 chip—is worth considering over a phone or Mac. It does receive a fantastic feature, but otherwise, it doesn't significantly differ from the iPhone updates. The iPad will have full home screen customization, a redesigned Photos app, and more.

However, the standout feature is the newly introduced Calculator app. Initially, I was prepared to criticize the launch, thinking, “Really? This is the big news?” But they showcased something called Math Notes, allowing users to handwrite equations, which the device can recognize and solve in your handwriting. If you update the equation, it will automatically adjust the answer. It also supports variables, enabling you to solve equations while seeing real-time graphs—a really impressive addition for users.

Interestingly, they hadn’t mentioned "AI" at all during the main part of the keynote. This handwriting recognition and semantic understanding clearly fall under AI capabilities—a clever move from Craig. But that’s before the actual AI section.

Now for macOS, the newest version is called Sequoia, featuring a collection of new tools. There's automatic window snapping, eliminating the need for a third-party app, and a password manager that now stands alone as an app instead of being buried in settings.

The most notable feature is iPhone Mirroring, which allows you to effortlessly see your iPhone screen on your Mac wirelessly. It merges notifications and audio from your iPhone to your Mac, making it convenient to drag and drop files back and forth. I do wonder about the impact on battery life, but if you’re just charging, it shouldn't be an issue.

Now, we arrived at the section where Apple would discuss AI. They finally addressed it following months of speculation about why they were avoiding the term. Apple has rebranded the concept as "Apple Intelligence." It's worth noting that Apple has already had AI features, like the Neural Engine in their chips, smart subject removal in photos, and auto-complete on keyboards. 

This new Apple Intelligence combines generative models and new functionalities. However, these features are only available on the highest-end versions of Apple silicon: the iPhone 15 Pro, and any iPad or Mac with M1 or later.

In the latest OSs, there’s a collection of tools that are spread across various applications; there’s no standalone Apple Intelligence app. For instance, in writing tools, you can now use large language models in apps like Pages or Keynote to summarize or rewrite text, change writing styles, or proofread.

Another feature, similar to Google Photos' Magic Eraser, is the Clean Up tool in the Photos app, letting you identify background items and eliminate them seamlessly while filling in the space with generative fill.

There’s also a new feature called Genmojis, allowing users to create emojis from scratch based on text prompts. Additionally, an Image Playground in various Apple apps lets you generate images in three styles: sketch, illustration, and animation.

Siri improvements will provide better context understanding, and later this year, it will be able to pull information from within apps to assist you better. There’s also a new full-screen animation for Siri activation, an updated voice, and the option to type to Siri instead of speaking—an overdue but welcome addition.

Apple has implemented notes and phone call summaries and sprinkled many more features throughout. I plan to create a dedicated video to delve deeper into Apple Intelligence soon, so keep an eye out for that.

There have been questions about what processing occurs on-device versus in the cloud. Apple partnered with OpenAI to integrate ChatGPT-4.0 into their Apple Intelligence framework. According to Apple, most features operate on-device using Apple-built models. If a task is too complex, it will utilize a larger cloud-based model on Apple servers.

If you request something through ChatGPT, a prompt will clarify whether it's acceptable to proceed—keeping the user in control. Importantly, OpenAI cannot store requests, and Apple ensures IP addresses are obscured to maintain user privacy.

In summary, many of these WWDC announcements indicate that even if other devices like the Humane Pin and the Rabbit R1 had something to offer, it can’t compete with the personalized capabilities of your phone. I believe we are entering a new era with Apple. The AI features are overshadowing even the most notable non-AI updates like home screen customization.

I’m genuinely excited about what this intelligence can deliver. I’ll be working on videos soon covering all of this, so make sure to subscribe if you haven’t already. Thanks for watching, and I’ll catch you in the next one. Peace.
(gentle music)