(lively music)  
- Is this another Vision Pro video?  
- Uh, yes. Yeah. It's a good one though, I promise.  
- Yeah, mm-hm. I'm sure.  
- No. Okay. So I’ve been thinking a lot about what a second-generation Vision Pro might look like.  
- But didn't this literally just come out?  
- No, I know, but okay, so obviously, there are lots of other VR headsets, but there are lots of things that got way more interesting about this one joining the market. And if you compare this to those, this is missing some stuff.  
- Right, but those are also the most expensive ones.  
- Yeah, yeah, yeah. There are things that the Quest 3 does that if the Vision Pro did it, it would feel like a revolutionary change to this thing. It’s a good video, I swear.  
- All right. I’ll allow it.  
- This doesn’t work though. You can’t.  
- Okay. Fine.  
- Anyway.  
(upbeat music)  
(logo whooshes)  
So I don’t think the Vision Pro is going to be an every single year product update, like the iPhone. I think it's going to be one of those kinds of products that comes out every couple of years. You stack up enough tech updates every once in a while, and then it’s worthy of a new generation. It’s a bigger deal when it comes out. And by the way, that’s how a lot of other VR headsets have been. The Quest 3 came out three years after the Quest 2, and the PS VR 2 came out six years after the first one. 

So, in a sense, these are already very early thoughts, but it’s been out for a little bit, and we’re really starting to get a sense of where people are using it and how they’re getting the most value out of it. Let me tell you, a lot of people are still not convinced about the whole VR or Vision Pro thing at all. It’s an interesting product for sure, but it just doesn’t do much. I started having those thoughts immediately as soon as I began testing this thing—just all sorts of missing features that I would like it to have. 

So here are those thoughts all in one place. Probably the biggest thing that you’ve noticed, if you’ve been familiar with the VR headset world or used any other VR headset before, is that the Vision Pro is missing shared experiences. With it, you are always alone in this headset. There are lots of great, super immersive experiences, and you can be productive and watch a movie, but no matter what's happening, you're always alone. Even if you have pass-through on, nobody else can see what you see. So it's basically impossible to share what you’re experiencing without mirroring everything on an iPad or something like that. 

Now, FaceTime is close. It’s one thing, but I’m talking about sharing one virtual space with more than one person, or seeing the same virtual environment at the same time with multiple people, or seeing the same virtual object from two different perspectives at the same time. You ever play "Rec Room"? It’s one of the oldest but most fun games on the Meta Quest. It’s just so simple. You’re out there having fun, running around a room, or in different game areas where you can jump into an experience and play a game together. 

In that digital space, you can look around and see other people—well, I use "people" with air quotes—but you see them, they see you, and you can explore the same environment from different angles at the same time. It doesn’t even have to be super realistic or high resolution to convince you that it’s another reality, but it’s way more social and interactive and fun that way. On the Apple Vision Pro, aside from FaceTime, really, all of the other experiences are just you in there solo. There’s no one else in there. 

So, no matter what you’re doing, no matter how immersive the movie is or how good the game is around you, you’re in there by yourself, and nobody else can see what you’re seeing. Here’s a basic example: How cool would it be if you and the person next to you on a plane could sync up your experiences and both watch the same movie in a virtual theater at the same time? Simple as that. Or, maybe if you were manipulating a 3D object in space, wouldn’t it make a ton of sense for someone else to be able to share that object with you so they can see how you’re manipulating it? It just feels like it makes too much sense. 

I told you guys about that Sky Guide app, which shows you the stars and constellations in the sky. It’s pretty awesome. Funny enough, there's a laser pointer feature that lets you point at the sky and circle around and point at things. But still, nobody can see what you’re pointing at with the laser, even if they have a Vision Pro. 

So there are two basic types of shared experiences that it would be great for Apple to add to this device. The first is if two different people with Vision Pros are in the same room with pass-through on, one of them could drop a virtual object into that room, and the other can see and manipulate it at the same time. Great. The second is when two different people with Vision Pros are in different locations, halfway across the world, it doesn’t matter. They both turn on or join the same virtual environment and can see it at the same time. 

As of right now, I believe the first type is harder because of how these headsets work with the pass-through. They are basically in real time mapping the volume of space around you with the sensors on the front—mapping surfaces, walls, floors, and objects around you. That’s how Vision OS locks your apps floating in 3D space and casts shadows on different surfaces in your room with decent accuracy. But there’s no guarantee that if you’re in a room with someone else who also has a headset on, both your headsets are mapping the room in the exact same way. 

Maybe I place an object into space, but your headset doesn’t see that space, so it gets confused, or it doesn’t map my hands or what I’m manipulating in precisely the same way. It’s not guaranteed to be the same. The other kind, sharing a virtual environment that someone builds with anyone anywhere in the world, seems like a no-brainer. Like, being able to watch a movie in a virtual movie theater with someone else who gets a seat in that theater or playing a multiplayer game in the same environment—this stuff is pretty basic with VR. 

I love playing multiplayer table tennis in the Quest. It’s one of my favorite shared VR experiences. You can play against people anywhere else in the world. There are all kinds of other multiplayer games like this in VR. That is a huge part of the VR gaming experience, and I just wonder why this doesn’t have that yet. It seems like a significant oversight, especially since Apple has built massive, high-resolution environments, but you can only move a little bit before you’re out of the play zone. It’s fascinating. I wonder if that’s related to how Apple thinks about these environments. 

Nevertheless, I know that’s the number one missing feature on the Vision Pro that I’d love to see in a second generation. Now, the other big one that stands out to me is, if I want to use the Vision Pro a lot in multiple locations—home and work—I wish it had a memory of all the windows and apps I leave open in each place. 

See, the Vision Pro is already amazing in one space. It’s seriously incredible. Windows stay locked to where you leave them as the device live maps your space. You can pin something to a wall, then walk around and pin something to another wall or right in the middle of the room. Leave the room, come back, and they’re still there. I even tried this: I pinned a window between two cars in a parking lot, turned, and walked away. I went inside, walked down a long hallway, totally out of sight, around another corner into the studio—and sure enough, that window is still right where I left it between those spaces in the parking lot. 

The only thing holding it back from being nearly perfect is occlusion. Basically, the only thing that gets between the window and you is your own arms and hands, which is usually fine. But if you have something positioned around a corner, it doesn’t put the wall in between you and the window, which is where it should be. Sometimes it gets a little wonky, but overall, it’s a 9 out of 10—already really cool. 

However, the second it gets dinged is when you want to do this in more than one space. So, let's say at home, I've set up all these virtual monitors, with a virtual TV in one room and some windows on the walls. I pack it up, drive to the studio, and put it on. The second I start opening apps here, they have to disappear from home. They basically disappear from any other space and open in your new space. So, there’s no memory of different older spaces, so when I go back home, my windows are all gone, and I’ll have to set them up again one by one. Not a huge deal, but if it had memory, wouldn’t that make sense? 

I wonder if you could set up little beacons. All it probably needs is a QR code or some visual identifier. You get home, put the headset on, and it sees the beacon and goes, “Oh, I’m at home,” then puts all your windows back where you usually have them for work. Basically, you kick back on the couch, put the headset on, and you don’t have to re-set up each window in all the same places every time. It would just remember that. 

Those two features alone would dramatically update how often I would realistically use the Vision Pro. I don’t know if that requires a Vision OS software update or if you need more computational power for shared spaces, but those are the significant things I think are missing that would be awesome. 

Then the rest of the stuff on my list is maybe a little more icing on the cake. For example, I think probably 99.99% of people who buy a Vision Pro have an iPhone. I think that’s pretty safe. It might be a hundred percent, but I think that’s reasonable. I found it interesting that a lot of people assume it’ll just connect to the iPhone, thinking they'll see their phone notifications straight away on the Vision Pro, but it's not. It’s a separate device, like a Mac or an iPad. 

So, yeah, it will show you iMessage notifications, but it is a separate device. Unlike a Mac or iPad, when you put on a headset, you’re automatically wearing it. So if I get a phone call on my iPhone, I can’t necessarily even see that I’m getting a call. There is no notification for it in the Vision Pro, and I have to take the headset off to see it and accept the call. So, it would be nice to have an option where these two devices communicated a bit better—maybe a little hub for smartphone notifications if I want to check them. I think it makes sense. They probably won’t do that though. 

But here’s a number for you: 3,386. That is the pixel density of the Vision Pro’s displays. It’s a pretty ridiculous number—over 3,000 pixels per inch each. There have been some teardowns; I’ll link those below. You can see the displays up close—they’re incredibly sharp. So that, along with the high refresh rate and minimal distortion, contributes to the pass-through feeling very real. 

However, the number I’d like to improve is 92. The Vision Pro’s displays show 92% of the DCI-P3 color gamut. That’s pretty good coverage for a display, honestly. The reference-grade display, like the Pro Display XDR, will show you 99% of DCI-P3. So again, it’s great for a display, but the thing about a VR headset is it’s replacing your eyes. The pass-through is decent for what it is, but without getting too complicated, 100% coverage of DCI-P3 represents about 50% coverage of all the colors the human eye can see. 

So this headset looks great and is very sharp, but it’s only showing me a little less than half of the colors of reality. I wonder how much they can improve that because the human eye is obviously capable of incredible dynamic range and sharpness. Apple has a long-standing reputation for great displays, and these are no exception, but a wider field of view and more color depth would be interesting. 

There are also a lot of other little things that are obvious, like weight reduction—of course. Higher quality screen recording is a niche request of mine, but I think it would help a lot for people trying to create videos with these things. Additionally, even more specific, keyboard pass-through while in an environment would be great. So you’re in an environment typing on a virtual Mac display, and if it can recognize my hands after a scan, I think it would be nice to have a feature that scans your keyboard or recognizes the keyboard of your MacBook. After all, it’s going to look the same every time, just like my hands. 

All that being said, I’m sure there are more things on other people's lists. Let me know what you think about the Apple Vision Pro gen two. Maybe leave your wishlist in the comments below. Thanks for watching. Catch you guys on the next one. Peace.  
(lively music)