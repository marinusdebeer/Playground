{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym-super-mario-bros==7.4.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (7.4.0)\n",
      "Requirement already satisfied: nes-py>=8.1.4 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from gym-super-mario-bros==7.4.0) (8.2.1)\n",
      "Requirement already satisfied: gym>=0.17.2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (1.24.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (1.5.21)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (4.66.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (3.17.0)\n",
      "Requirement already satisfied: tensordict==0.3.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from tensordict==0.3.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from tensordict==0.3.0) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from tensordict==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->tensordict==0.3.0) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from jinja2->torch>=2.1.0->tensordict==0.3.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from sympy->torch>=2.1.0->tensordict==0.3.0) (1.3.0)\n",
      "Requirement already satisfied: torchrl==0.3.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch>=2.1.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchrl==0.3.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchrl==0.3.0) (1.24.4)\n",
      "Requirement already satisfied: packaging in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchrl==0.3.0) (23.2)\n",
      "Requirement already satisfied: cloudpickle in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchrl==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: tensordict>=0.3.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchrl==0.3.0) (0.3.0)\n",
      "Requirement already satisfied: filelock in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch>=2.1.0->torchrl==0.3.0) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from jinja2->torch>=2.1.0->torchrl==0.3.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from sympy->torch>=2.1.0->torchrl==0.3.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym-super-mario-bros==7.4.0\n",
    "!pip install tensordict==0.3.0\n",
    "!pip install torchrl==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (0.17.0)\n",
      "Requirement already satisfied: matplotlib in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: numpy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from torch==2.2.0->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from requests->torchvision) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from jinja2->torch==2.2.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages (from sympy->torch==2.2.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/marinus/miniconda3/envs/mario/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# Initialize Super Mario environment (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='rgb', apply_api_compatibility=True)\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
    "else:\n",
    "    env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "        self.net = self.net.to(device=self.device)\n",
    "\n",
    "        self.exploration_rate = 0.8\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e3  # no. of experiences between saving Mario Net\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    Given a state, choose an epsilon-greedy action and update value of step.\n",
    "\n",
    "    Inputs:\n",
    "    state(``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
    "    Outputs:\n",
    "    ``action_idx`` (``int``): An integer representing which action Mario will perform\n",
    "    \"\"\"\n",
    "        # EXPLORE\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # EXPLOIT\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):  # subclassing for continuity\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done,))\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarioNet(nn.Module):\n",
    "    \"\"\"mini CNN structure\n",
    "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim)\n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        # Q_target parameters are frozen.\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "\n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\")\n",
    "        torch.save(dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate), save_path)\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
    "    \n",
    "    def load(self, file_name=None):\n",
    "        checkpoint = torch.load(file_name)\n",
    "        self.net.load_state_dict(checkpoint['model'])\n",
    "        self.exploration_rate = checkpoint['exploration_rate']\n",
    "        print(f\"Loaded MarioNet from {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "\n",
      "Loaded MarioNet from checkpoints/trained_mario.chkpt\n",
      "Episode 0 - Step 40 - Epsilon 0.1 - Mean Reward 231.0 - Mean Length 40.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 0.377 - Time 2024-02-20T22:08:07\n",
      "Episode 20 - Step 3823 - Epsilon 0.1 - Mean Reward 1011.524 - Mean Length 182.048 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 25.85 - Time 2024-02-20T22:08:33\n",
      "MarioNet saved to checkpoints/2024-02-20T22-08-07/mario_net_1.chkpt at step 5000\n",
      "Episode 39 - Step 7716 - Epsilon 0.1 - Mean Reward 1102.575 - Mean Length 192.9 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 25.045 - Time 2024-02-20T22:08:58\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "mario.load(\"checkpoints/trained_mario.chkpt\")\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 40\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mario",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
