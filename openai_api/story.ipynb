{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import textwrap\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import requests\n",
    "from io import BytesIO\n",
    "# voice_id = \"Ruth\"\n",
    "voice_id = \"Matthew\"\n",
    "output_format = \"mp3\"\n",
    "\n",
    "# Create an Amazon Polly client\n",
    "polly_client = boto3.Session(\n",
    "    aws_access_key_id='AKIAWN6557C6L2SLN77M',\n",
    "    aws_secret_access_key='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',\n",
    "    region_name='ca-central-1').client('polly')\n",
    "\n",
    "message_history = [{\"role\": \"system\", \"content\": \"\"\"You are an interactive story game bot that proposes some hypothetical fantastical sci-fi situation involving space travel where the user needs to pick from 2-4 options that you provide. Once the user picks one of those options, you will then state what happens next and present new options, and this then repeats. When you present the story and options, present just the story and start immediately with the story, no further commentary, and then options like \"Option 1:\" \"Option 2:\" ...etc. Don't start the story with Great or anything like that.\"\"\"}]\n",
    "\n",
    "story_build = \"hypothetical fantastical sci-fi situation involving space travel\\n\"\n",
    "def generate_story(input):\n",
    "  start_time = time.time()\n",
    "  completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\", \n",
    "      messages=input)\n",
    "  reply_content = completion.choices[0].message.content\n",
    "  # print(f\"Generate Story Took: {time.time() - start_time}\")\n",
    "\n",
    "  generate_image(reply_content)\n",
    "  # split_wrap(reply_content)\n",
    "  return reply_content\n",
    "\n",
    "# Function to load an image from a URL into a reportlab Image object\n",
    "def load_image_from_url(url, width=None, height=None):\n",
    "    response = requests.get(url)\n",
    "    img = Image(BytesIO(response.content), width, height)\n",
    "    return img\n",
    "\n",
    "def generate_image(input):\n",
    "  global images\n",
    "  global story_build\n",
    "  lines = input.split('\\n')\n",
    "  filtered_lines = [line for line in lines if not line.strip().lower().startswith(\"option\")]\n",
    "  new_text = '\\n'.join(filtered_lines)\n",
    "  if story_build is not None:\n",
    "    story_build = story_build + \"\\n\" + new_text\n",
    "  else:\n",
    "    story_build = new_text\n",
    "  split_wrap(story_build)\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Generate a summary based on the following: \\n\" + new_text,\n",
    "    # prompt=\"Generate a summary based on the following: \\n\" + story_build,\n",
    "    max_tokens=100,\n",
    "    temperature=0.5\n",
    "  )\n",
    "  res = response.choices[0].text\n",
    "  # split_wrap(\"Image generator prompt: \\n\" + res)\n",
    "  start_time = time.time()\n",
    "  response = openai.Image.create(\n",
    "    prompt=new_text,\n",
    "    n=1,\n",
    "    size=\"512x512\"\n",
    "  )\n",
    "  image_url = response['data'][0]['url']\n",
    "  images.append(image_url)\n",
    "  display(IPImage(url=image_url))\n",
    "  split_wrap(input)\n",
    "  # print(image_url)\n",
    "  # print(f\"Generate Image Took: {time.time() - start_time}\")\n",
    "  return response\n",
    "\n",
    "\n",
    "def add_text_below_image(image, text, font_path=None):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default() if font_path is None else ImageFont.truetype(font_path, size=16)\n",
    "\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "    new_image = Image.new(\"RGB\", (max(image.width, text_width), image.height + text_height + 10), (255, 255, 255))\n",
    "    \n",
    "    new_image.paste(image, (0, 0))\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "    draw.text(((new_image.width - text_width) // 2, image.height + 5), text, font=font, fill=(0, 0, 0))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "\n",
    "def split_wrap(input):\n",
    "  lines = input.split('\\n')\n",
    "  wrapped_lines = [textwrap.fill(line, width=60) for line in lines]\n",
    "  wrapped = '\\n'.join(wrapped_lines)\n",
    "  print(wrapped)\n",
    "  return wrapped\n",
    "\n",
    "def generate_audio(input, count):\n",
    "  start_time = time.time()\n",
    "  audio = polly_client.synthesize_speech(\n",
    "      Text=input,\n",
    "      VoiceId=voice_id,\n",
    "      OutputFormat=output_format,\n",
    "      Engine=\"neural\"\n",
    "      )\n",
    "  # print(f\"Generate Audio Took: {time.time() - start_time}\")\n",
    "  save_audio(audio, count)\n",
    "  return audio\n",
    "\n",
    "from google.cloud import texttospeech\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"google_cloud_text_speech_key.json\"\n",
    "def synthesize_speech(text, output_filename):\n",
    "  # Create a Text-to-Speech client\n",
    "  client = texttospeech.TextToSpeechClient()\n",
    "  input_text = texttospeech.SynthesisInput(text=text)\n",
    "  voice = texttospeech.VoiceSelectionParams(\n",
    "      language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n",
    "  audio_config = texttospeech.AudioConfig(\n",
    "      audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "  response = client.synthesize_speech(\n",
    "      input=input_text, voice=voice, audio_config=audio_config\n",
    "  )\n",
    "  with open(output_filename, \"wb\") as out:\n",
    "      out.write(response.audio_content)\n",
    "      # print(f\"Audio content written to '{output_filename}'\")\n",
    "\n",
    "def save_audio(response, count):\n",
    "  with open(f\"output{count}.mp3\", \"wb\") as f:\n",
    "      f.write(response[\"AudioStream\"].read())\n",
    "\n",
    "def read_audio(file):\n",
    "  command = [\"C:\\\\Program Files (x86)\\\\Windows Media Player\\\\wmplayer.exe\", '/play', '/close', f\"C:/Users/Marinus/OneDrive/Desktop/Development/Playground/openai_api/{file}\"]\n",
    "  process = subprocess.Popen(command)\n",
    "  return process\n",
    "\n",
    "def generate_pdf(input):\n",
    "  # Create a PDF document\n",
    "  doc = SimpleDocTemplate(f\"stories/output_{time.time()}.pdf\", pagesize=letter)\n",
    "  styles = getSampleStyleSheet()\n",
    "  pdf = []\n",
    "  for i in range(len(input)):\n",
    "    image = load_image_from_url(images[i], width=300, height=300)\n",
    "    pdf.append(image)\n",
    "    pdf.append(Spacer(1, 12))\n",
    "\n",
    "    # Add the text below the image to the PDF\n",
    "    paragraph = Paragraph(input[i], styles[\"Normal\"])\n",
    "    pdf.append(paragraph)\n",
    "    pdf.append(Spacer(1, 12))\n",
    "  doc.build(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "done = False\n",
    "images = []\n",
    "\n",
    "while not done:\n",
    "  story = generate_story(message_history)\n",
    "  message_history.append({\"role\": \"assistant\", \"content\": story})\n",
    "  # audio = synthesize_speech(story, f\"output{count}.mp3\")\n",
    "  audio = generate_audio(story, count)\n",
    "  # save_audio(audio, count)\n",
    "  media_player = read_audio(f\"output{count}.mp3\")\n",
    "  while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower().strip() in [\"exit\", \"quit\"]:\n",
    "      media_player.terminate()\n",
    "      done = True\n",
    "      break\n",
    "    if re.search(r\"\\S\", user_input):\n",
    "      media_player.terminate()\n",
    "      message_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "      count += 1\n",
    "      print(\"\\n\")\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid input, please try again\")\n",
    "print(\"End of story\")\n",
    "\n",
    "messages = []\n",
    "for i, message in enumerate(message_history):\n",
    "  if message['role'] == \"assistant\":\n",
    "    split_wrap(message['content'])\n",
    "    messages.append(message['content'])\n",
    "    print()\n",
    "\n",
    "generate_pdf(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
