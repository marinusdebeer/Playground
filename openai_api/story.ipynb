{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eendag, in 'n klein dorpie in Afrika, was daar 'n klein seuntjie genaamd Lucas. Lucas was lief vir avontuur en was altyd nuuskierig. Hy het gehou om die woude rondom sy huis te verken. Eendag het hy 'n helder blinkende steen in die rivier opgemerk. Dit was 'n pragtige edelsteen! Hy het die steen aan sy vriende in die dorpie gewys en hulle was verstom. Sy ontdekking het hom die held van die dag gemaak en sedertdien was hy bekend as Lucas die Skathouer. Elke dag het Lucas 'n nuwe avontuur gesoek, altyd met 'n glimlag en die blinkende edelsteen in sy hand.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a very short story in afrikaans\"}\n",
    "  ]\n",
    ")\n",
    "message = completion.choices[0].message.content\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"speech8.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  speed = 1.0,\n",
    "  input=\"Once upon a time in the charming town of Melony, lived a small boy named Peter. Peter was well known for his curious nature and adventurous spirit. Every morning, he would put on his old gray hat, tie up his worn-out boots, grab his handful of curiously picked tools, and stroll down to the heart of the town where the Magical Blacksmith resided.\"\n",
    ")\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "image1 = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"A cute baby sea otter\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-0bJMKHctQAJbD2BLQXSVneDO/user-CHf8eCCjwcVPE8d9ZUnGIARB/img-48ImcnwiNXrUZ2JmBNcGrHHz.png?st=2023-11-07T00%3A32%3A52Z&se=2023-11-07T02%3A32%3A52Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-06T18%3A24%3A21Z&ske=2023-11-07T18%3A24%3A21Z&sks=b&skv=2021-08-06&sig=P7XsFGJzok2DRbwKnDY4QSRXRFwE6OqQjwwOAgcPd10%3D'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-0bJMKHctQAJbD2BLQXSVneDO/user-CHf8eCCjwcVPE8d9ZUnGIARB/img-cw1I5zmGUuhWxlnKmk13HysW.png?st=2023-11-07T09%3A13%3A46Z&se=2023-11-07T11%3A13%3A46Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-06T17%3A19%3A04Z&ske=2023-11-07T17%3A19%3A04Z&sks=b&skv=2021-08-06&sig=gbdeQjQygAwGh82vSshsXXIAZukNqAmqZqJKxo6XW78%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "# Image(url=image.data[0].url)\n",
    "Image(url=image1.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/1_/8tjkkw0s5k7bhzr96pfx40dr0000gn/T/tmp4bhdt3dw.wav':\n",
      "  Duration: 00:00:34.82, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "  34.78 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def stream_and_play():\n",
    "  response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Eendag, in 'n klein dorpie in Afrika, was daar 'n klein seuntjie genaamd Lucas. Lucas was lief vir avontuur en was altyd nuuskierig. Hy het gehou om die woude rondom sy huis te verken. Eendag het hy 'n helder blinkende steen in die rivier opgemerk. Dit was 'n pragtige edelsteen! Hy het die steen aan sy vriende in die dorpie gewys en hulle was verstom. Sy ontdekking het hom die held van die dag gemaak en sedertdien was hy bekend as Lucas die Skathouer. Elke dag het Lucas 'n nuwe avontuur gesoek, altyd met 'n glimlag en die blinkende edelsteen in sy hand.\",\n",
    "  )\n",
    "\n",
    "  # Convert the binary response content to a byte stream\n",
    "  byte_stream = io.BytesIO(response.content)\n",
    "\n",
    "  # Read the audio data from the byte stream\n",
    "  audio = AudioSegment.from_file(byte_stream, format=\"mp3\")\n",
    "\n",
    "  # Play the audio\n",
    "  play(audio)\n",
    "\n",
    "stream_and_play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import set_api_key\n",
    "set_api_key(\"2b38c4806cb40c59482a7192bc52834a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import set_api_key\n",
    "import os\n",
    "set_api_key(\"2b38c4806cb40c59482a7192bc52834a\")\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from elevenlabs import generate, stream, voices, play\n",
    "response = openai.ChatCompletion.create(\n",
    "        # model='gpt-4',\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role': 'user', 'content': 'Tell me a very short story'}],\n",
    "        temperature=1,\n",
    "        stream=True)\n",
    "def text_iterator():\n",
    "    for chunk in response:\n",
    "      delta = chunk['choices'][0][\"delta\"]\n",
    "      if \"content\" in delta:\n",
    "          print(delta.content, end=\" \")\n",
    "          yield delta[\"content\"]\n",
    "audio_stream = generate(\n",
    "  text=text_iterator(),\n",
    "  stream=True,\n",
    "  voice=\"UNTwJ911HFesFGfyg0mf\"\n",
    ")\n",
    "stream(audio_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import generate, play\n",
    "from elevenlabs import generate, stream\n",
    "\n",
    "brian_stream = generate(\n",
    "    text=\"\"\"In the vast expanse of time and the infinity of the universe, consider the fleeting nature of your own existence. To be perturbed by trivial matters is to lose sight of the harmony that governs all. Focus not on the judgments of others or the clamor of the masses, but on the steady path of virtue and wisdom. For in the end, it is not by the applause of the world that one is measured, but by the integrity of one's own soul.\"\"\",\n",
    "    # voice=\"0TDBPMDKSUgUcFOHD3h4\", #markus_authoritative\n",
    "    # voice=\"UNTwJ911HFesFGfyg0mf\", #brian\n",
    "    model='eleven_monolingual_v1',\n",
    "    voice = 'Brian',\n",
    "    stream=False\n",
    ")\n",
    "play(brian_stream)\n",
    "# stream(brian_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to extract images from PDF\n",
    "def extract_images(pdf_path, output_folder):\n",
    "    images = convert_from_path(pdf_path)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"{output_folder}/image_{i}.png\", \"PNG\")\n",
    "\n",
    "# Usage example\n",
    "pdf_path = \"stories/output_1679753240.883668.pdf\"\n",
    "output_folder = \"output_images\"\n",
    "\n",
    "text = extract_text(pdf_path)\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "extract_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_hyperlinked_urls(pdf_path):\n",
    "    urls = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Get annotations from the page\n",
    "            annotations = page.annots\n",
    "            \n",
    "            if annotations is not None:\n",
    "                for annot in annotations:\n",
    "                    print(annot['uri'])\n",
    "                    # Check if the annotation is a URI (URL) action\n",
    "                    if \"Subtype\" in annot and annot[\"Subtype\"] == \"Link\" and \"A\" in annot and annot[\"A\"][\"S\"] == \"URI\":\n",
    "                        urls.append(annot[\"A\"][\"URI\"])\n",
    "                        \n",
    "    return urls\n",
    "\n",
    "# Usage example\n",
    "pdf_path = \"stories/output_1679753240.883668.pdf\"\n",
    "\n",
    "urls = extract_hyperlinked_urls(pdf_path)\n",
    "print(\"Extracted URLs:\")\n",
    "for url in urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import textwrap\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "# voice_id = \"Ruth\"\n",
    "voice_id = \"Matthew\"\n",
    "output_format = \"mp3\"\n",
    "\n",
    "# Create an Amazon Polly client\n",
    "polly_client = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"polly_access_key_id\"),\n",
    "    aws_secret_access_key=os.getenv(\"polly_secret_key\"),\n",
    "    region_name='ca-central-1').client('polly')\n",
    "\n",
    "message_history = [{\"role\": \"system\", \"content\": \"\"\"You are an interactive story game bot that proposes some hypothetical fantastical sci-fi situation involving space travel where the user needs to pick from 2-4 options that you provide. Once the user picks one of those options, you will then state what happens next and present new options, and this then repeats. When you present the story and options, present just the story and start immediately with the story, no further commentary, and then options like \"Option 1:\" \"Option 2:\" ...etc. Don't start the story with Great or anything like that.\"\"\"}]\n",
    "\n",
    "story_build = \"hypothetical fantastical sci-fi situation involving space travel\\n\"\n",
    "def generate_story(input):\n",
    "  start_time = time.time()\n",
    "  completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\", \n",
    "      messages=input)\n",
    "  reply_content = completion.choices[0].message.content\n",
    "  # print(f\"Generate Story Took: {time.time() - start_time}\")\n",
    "\n",
    "  generate_image(reply_content)\n",
    "  # split_wrap(reply_content)\n",
    "  return reply_content\n",
    "\n",
    "# Function to load an image from a URL into a reportlab Image object\n",
    "def load_image_from_url(url, width=None, height=None):\n",
    "    response = requests.get(url)\n",
    "    img = Image(BytesIO(response.content), width, height)\n",
    "    return img\n",
    "def generate_image_prompt(input):\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Generate a summary based on the following: \\n\" + input,\n",
    "    # prompt=\"Generate a summary based on the following: \\n\" + story_build,\n",
    "    max_tokens=100,\n",
    "    temperature=0.5\n",
    "  )\n",
    "  res = response.choices[0].text\n",
    "  print(\"Image Prompt: \\n\" + res)\n",
    "  return res\n",
    "def generate_image(input):\n",
    "  global images\n",
    "  global story_build\n",
    "  lines = input.split('\\n')\n",
    "  filtered_lines = [line for line in lines if not line.strip().lower().startswith(\"option\")]\n",
    "  prompt = '\\n'.join(filtered_lines)\n",
    "  if story_build is not None:\n",
    "    story_build = story_build + \"\\n\" + prompt\n",
    "  else:\n",
    "    story_build = prompt\n",
    "  # split_wrap(story_build)\n",
    "\n",
    "  # prompt = generate_image_prompt(prompt)\n",
    "  # split_wrap(\"Image generator prompt: \\n\" + res)\n",
    "  start_time = time.time()\n",
    "  response = openai.Image.create(\n",
    "    prompt=\"Science fiction, \" + prompt,\n",
    "    n=1,\n",
    "    size=\"512x512\"\n",
    "  )\n",
    "  image_url = response['data'][0]['url']\n",
    "  images.append(image_url)\n",
    "  display(IPImage(url=image_url))\n",
    "  split_wrap(input)\n",
    "  # print(image_url)\n",
    "  # render_story(input, image_url)\n",
    "  # print(image_url)\n",
    "  # print(f\"Generate Image Took: {time.time() - start_time}\")\n",
    "  return response\n",
    "\n",
    "\n",
    "def add_text_below_image(image, text, font_path=None):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default() if font_path is None else ImageFont.truetype(font_path, size=16)\n",
    "\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "    new_image = Image.new(\"RGB\", (max(image.width, text_width), image.height + text_height + 10), (255, 255, 255))\n",
    "    \n",
    "    new_image.paste(image, (0, 0))\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "    draw.text(((new_image.width - text_width) // 2, image.height + 5), text, font=font, fill=(0, 0, 0))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "\n",
    "def split_wrap(input):\n",
    "  lines = input.split('\\n')\n",
    "  wrapped_lines = [textwrap.fill(line, width=60) for line in lines]\n",
    "  wrapped = '\\n'.join(wrapped_lines)\n",
    "  print(wrapped)\n",
    "  return wrapped\n",
    "\n",
    "def generate_audio(input, count):\n",
    "  start_time = time.time()\n",
    "  audio = polly_client.synthesize_speech(\n",
    "      Text=input,\n",
    "      VoiceId=voice_id,\n",
    "      OutputFormat=output_format,\n",
    "      Engine=\"neural\"\n",
    "      )\n",
    "  # print(f\"Generate Audio Took: {time.time() - start_time}\")\n",
    "  save_audio(audio, count)\n",
    "  return audio\n",
    "\n",
    "from google.cloud import texttospeech\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"google_cloud_text_speech_key.json\"\n",
    "def synthesize_speech(text, output_filename):\n",
    "  # Create a Text-to-Speech client\n",
    "  client = texttospeech.TextToSpeechClient()\n",
    "  input_text = texttospeech.SynthesisInput(text=text)\n",
    "  voice = texttospeech.VoiceSelectionParams(\n",
    "      language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n",
    "  audio_config = texttospeech.AudioConfig(\n",
    "      audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "  response = client.synthesize_speech(\n",
    "      input=input_text, voice=voice, audio_config=audio_config\n",
    "  )\n",
    "  with open(output_filename, \"wb\") as out:\n",
    "      out.write(response.audio_content)\n",
    "      # print(f\"Audio content written to '{output_filename}'\")\n",
    "\n",
    "def save_audio(response, count):\n",
    "  with open(f\"output{count}.mp3\", \"wb\") as f:\n",
    "      f.write(response[\"AudioStream\"].read())\n",
    "\n",
    "# def read_audio(file):\n",
    "#   # command = [\"C:\\\\Program Files (x86)\\\\Windows Media Player\\\\wmplayer.exe\", '/play', '/close', f\"C:/Users/Marinus/OneDrive/Desktop/Development/Playground/openai_api/{file}\"]\n",
    "#   # process = subprocess.Popen(command)\n",
    "\n",
    "#   audio = playsound(file)\n",
    "#   return audio\n",
    "\n",
    "import pygame\n",
    "def read_audio(file):\n",
    "  pygame.mixer.init()\n",
    "  pygame.mixer.music.load(file)\n",
    "  pygame.mixer.music.play()\n",
    "\n",
    "  # while pygame.mixer.music.get_busy():\n",
    "    # pygame.time.Clock().tick(10)\n",
    "  return pygame.mixer.music\n",
    "\n",
    "def generate_pdf(input):\n",
    "  # Create a PDF document\n",
    "  doc = SimpleDocTemplate(f\"stories/output_{time.time()}.pdf\", pagesize=letter)\n",
    "  styles = getSampleStyleSheet()\n",
    "  pdf = []\n",
    "  for i in range(len(input)):\n",
    "    image = load_image_from_url(images[i], width=300, height=300)\n",
    "    pdf.append(image)\n",
    "    pdf.append(Spacer(1, 12))\n",
    "\n",
    "    # Add the image URL as a clickable link below the image\n",
    "    image_url_link = f'<a href=\"{images[i]}\" color=\"blue\">Image {i+1}</a>'\n",
    "    image_url_paragraph = Paragraph(image_url_link, styles[\"Normal\"])\n",
    "    pdf.append(image_url_paragraph)\n",
    "    pdf.append(Spacer(1, 12))\n",
    "\n",
    "    # Add the text below the image to the PDF\n",
    "    input[i] = input[i].replace(\"\\n\", \"<br/>\")\n",
    "    paragraph = Paragraph(input[i], styles[\"Normal\"])\n",
    "    pdf.append(paragraph)\n",
    "    pdf.append(Spacer(1, 12))\n",
    "  doc.build(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "def render_story(message, image):\n",
    "\n",
    "    # Define your list of strings and images here\n",
    "    my_list = [\n",
    "        {'string': 'String 1', 'image': 'output_images/image_1.png'},\n",
    "        {'string': 'String 2', 'image': 'output_images/image_2.png'},\n",
    "        {'string': 'String 3', 'image': 'output_images/image_3.png'}\n",
    "    ]\n",
    "\n",
    "    # Initialize Pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Define the screen size\n",
    "    screen_width = 800\n",
    "    screen_height = 600\n",
    "\n",
    "    # Set up the display\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "\n",
    "    # Define the font and size\n",
    "    font = pygame.font.Font(None, 36)\n",
    "\n",
    "    # Define the current index in the list\n",
    "    index = 0\n",
    "\n",
    "    # Set up the clock\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    # Define a function to load images from external URLs\n",
    "    def load_image(url):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            image_data = response.read()\n",
    "        return pygame.image.load(pygame.compat.BytesIO(image_data))\n",
    "    # Define the game loop\n",
    "    while True:\n",
    "        # Handle events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_SPACE:\n",
    "                    # Increment the index when the user presses the space bar\n",
    "                    index += 1\n",
    "\n",
    "                    # if index >= len(messages):\n",
    "                    #     # If we've reached the end of the list, go back to the start\n",
    "                    #     index = 0\n",
    "\n",
    "        # Clear the screen\n",
    "        screen.fill((255, 255, 255))\n",
    "\n",
    "        # Load the current image and render it on the screen\n",
    "        image = load_image(image)\n",
    "        screen.blit(image, (0, 0))\n",
    "\n",
    "        # Render the current string on the screen\n",
    "        text = font.render(message, True, (0, 0, 0))\n",
    "        screen.blit(text, (10, 10))\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Set the frame rate\n",
    "        clock.tick(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "done = False\n",
    "images = []\n",
    "\n",
    "while not done:\n",
    "  story = generate_story(message_history)\n",
    "  message_history.append({\"role\": \"assistant\", \"content\": story})\n",
    "  # audio = synthesize_speech(story, f\"output{count}.mp3\")\n",
    "  audio = generate_audio(story, count)\n",
    "  media_player = read_audio(f\"output{count}.mp3\")\n",
    "  while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower().strip() in [\"exit\", \"quit\"]:\n",
    "      try:\n",
    "        media_player.stop()\n",
    "      except:\n",
    "        media_player.terminate()\n",
    "      done = True\n",
    "      break\n",
    "    if re.search(r\"\\S\", user_input):\n",
    "      try:\n",
    "        media_player.stop()\n",
    "      except:\n",
    "        media_player.terminate()\n",
    "      message_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "      count += 1\n",
    "      print(\"\\n\")\n",
    "      break\n",
    "    else:\n",
    "      print(\"Invalid input, please try again\")\n",
    "print(\"End of story\")\n",
    "\n",
    "messages = []\n",
    "for i, message in enumerate(message_history):\n",
    "  if message['role'] == \"assistant\":\n",
    "    split_wrap(message['content'])\n",
    "    messages.append(message['content'])\n",
    "    print()\n",
    "\n",
    "generate_pdf(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
