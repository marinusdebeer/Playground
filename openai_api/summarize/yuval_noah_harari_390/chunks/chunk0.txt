- If we now find ourselves inside this kind of world of illusions, created by an alien intelligence that we don't understand, but it understands us, this is a kind of, you know, spiritual enslavement that we won't be able to break out of, because it understands us, it understands how to manipulate us, but we don't understand what is behind this screen of stories and images and songs. - The following is a conversation with Yuval Noah Harari, a historian, philosopher, and author of several highly acclaimed, highly influential books, including "Sapiens", "Homo Deus", and "21 Lessons for the 21st Century". He is also an outspoken critic of Benjamin Netanyahu, and the current right wing government in Israel. So, while much of this conversation is about the history and future of human civilization, we also discuss the political turmoil of present day Israel, providing a different perspective from that of my recent conversation with Benjamin Netanyahu. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Yuval Noah Harari. 13.8 billion years ago is the origin of our universe. 3.8 billion years ago is the origin of life here on our little planet, the one we call Earth, let's say, 200,000 years ago is the appearance of early homo sapiens. So let me ask you this question. How rare are these events in the vastness of space and time? Or put it in a more fun way, how many intelligent alien civilizations do you think are out there in this universe? - Hmm. - Us being one of them. - I suppose there should be some, statistically, but we don't have any evidence. But I do think that, you know, intelligence in any way, it's a bit overvalued. We are the most intelligent entities on this planet. And look what you're doing. So intelligence also tends to be self-destructive, which implies that if there are, or were intelligent life forms elsewhere, maybe they don't survive for long. - So you think there's a tension between happiness and intelligence? - Absolutely. Intelligence is definitely not something that is directed towards amplifying happiness. I would also emphasize the huge, huge difference between intelligence and consciousness, which many people, certainly in the tech industry and in the AI industry, tend to miss. Intelligence is simply the ability to solve problems, to attain goals, and, you know, to win at chess, to win a struggle for survival, to win a war, to drive a car, to diagnose a disease. This is intelligence. Consciousness is the ability to feel things like pain and pleasure and love and hate. In humans and other animals, intelligence and consciousness go together, they go hand in hand, which is why we confuse them. We solve problems, we attain goals by having feelings. But other types of intelligence, certainly in computers, computers are already highly intelligent. And as far as we know, they have zero consciousness. When a computer beats you at chess or go or whatever, it doesn't feel happy. If it loses, it doesn't feel sad. And there could be also other highly intelligent entities out there in the universe that have zero consciousness. And I think that consciousness is far more important and valuable than intelligence. - Can you say to me on the case that consciousness and intelligence are intricately connected? So not just in humans, but anywhere else. They have to go hand in hand. Is it possible for you to imagine such a universe? - It could be, but we don't know yet. Again, we have examples, certainly we know of examples of high intelligence without consciousness. Computers are one example. As far as we know, plans are not conscious, yet they are intelligent. They can solve problems, they can attain goals in very sophisticated ways. So... The other way around, to have consciousness without any intelligence, this is probably impossible, but to have intelligence without consciousness, yes, that's possible. A bigger question is whether any of that is tied to organic biochemistry. We know on this planet only about carbon-based life forms. Whether you are an amoeba, a dinosaur, a tree, a human being, you are based on organic biochemistry. Is there an essential connection between organic biochemistry and consciousness? Do all conscious entities everywhere in the universe or in the future on planet Earth have to be based on carbon? Is there something so special about carbon as an element that an entity based on silicon will never be conscious? I don't know, maybe, but again, this is a key question about computer and computer consciousness, that can computers eventually become conscious even though they are not organic? The jury still out on that. I don't know. I mean, we have to take both options into account. - Well, a big part of that is do you think we humans would be able to detect other intelligent beings, other conscious beings? Another way to ask that, is it possible that the aliens are already here and we don't see them? Meaning, are we very human centric in our understanding of, one, the definition of life, two, the definition of intelligence, and three, the definition of consciousness? - The aliens are here. They're just not from outer space. AI, which usually stands for artificial intelligence, I think it stands for alien intelligence because AI is an alien type of intelligence. It solve problems, attains goals in a very, very different way, in an alien way from human beings. Yeah, I'm not implying that AI came from outer space, it came from Silicon Valley, but it is alien to us. If there are alien intelligent or conscious entities that came from outer space already here, I've not seen any evidence for it. It's not impossible, but, you know, in science, evidence is everything. - Well, I mean, I guess instructive, there's just having the humility to look around, to think about living beings that operate at a different timescale, at different spatial scale... And I think that's all useful when starting to analyze artificial intelligence. It's possible that even the language models, the large language models we have today are already conscious. - I highly doubt it, but I think consciousness in the end, it's a question of social norms. Because we cannot prove consciousness in anybody except ourselves. We know that we are conscious because we are feeling it. We have direct access to our subjective consciousness. We cannot have any proof that any other entity in the world, any other human being, our parents, our best friends, we don't have proof that they are conscious. You know, this has been known for thousands of years. This is Descartes, this is Buddha, this is Plato. We don't, we can't have this sort of proof. What we do have is social conventions. It's a social convention that all human beings are conscious. It also applies to animals. Most people who have pets firmly believe that their pets are conscious. But a lot of people still refuse to acknowledge that about cows or pigs. Now, pigs are far more intelligent than dogs and cats according to many measures. Yet, when you go to the supermarket and buy a piece of frozen pig meat, you don't think about it as a conscious entity. Why do you think of your dog as conscious, but not of the bacon that you buy? Because you've built a relationship with the dog and you don't have a relationship with the bacon. Now, relationships, they don't constitute a logical proof for consciousness. They're a social test. The Turing test is a social test. It's not a logical proof. Now, if you establish a mutual relationship with an entity where when you are invested in it emotionally, you are almost compelled to feel that the other side is also conscious. And when it comes again to AI and computers, I don't think that at the present moment computers are conscious, but people are already forming intimate relationships with AIs and are therefore it's almost irresistible. They're compelled to increasingly feel that these are conscious entities. And I think we are quite close to the point when the legal system will have to take this into account, that even though I don't think computers have consciousness, I think we are close to the point the legal system will start treating them as conscious entities because of this social convention. - What, to you, is a social convention just a funny little side effect, a little artifact? Or is it like fundamental to what consciousness is? Because if it is fundamental, then it seems like AI is very good at forming these kinds of deep relationships with humans. - Yeah. - And therefore it'll be able to be a nice catalyst for integrating itself into these social conventions of ours. - It was built to accomplish that. - Yeah. - We are design... Again, you know, all this argument between natural selection and creationism, intelligent design. As far as the past go, all entities evolve by natural selection. The funny thing is, when you look at the future, more and more entities will come out of intelligent design, not of some god above the clouds, but of our intelligent design and the intelligent design of our clouds, of our computing clouds. They will design more and more entities. And this is what is happening with AI. It is designed to be very good at forming intimate relationships with humans. And in many ways, it's already doing it almost better than human beings in some situations. You know, when two people talk with one another, one of the things that kind of makes the conversation more difficult is our own emotions. You are saying something and I'm not really listening to you because there is something I want to say, and I'm just waiting until you finish, I can put in a word, or I'm so obsessed with my anger or irritation or whatever, that I don't pay attention to what you are feeling. This is one of the biggest obstacles in human relationships. And computers don't have this problem, because they don't have any emotions of their own. So, you know, when a computer is talking to you, it can be the most, it can focus 100% of its attention is on what you are saying and what you are feeling, because it has no feelings of its own. And paradoxically, this means that computers can fool people into feeling that, oh, there is a conscious entity on the other side, an empathic entity on the other side. Because the one thing everybody wants almost more than anything in the world, is for somebody to listen to me, somebody to focus all their attention on me. Like I want it for my spouse, for my husband, for my mother, for my friends, for my politicians... Listen to me, listen to what I feel. And they often don't. And now you have this entity, which 100% of its attention is just on what I feel. And this is a huge, huge temptation. And I think also a huge, huge danger. - Well, the interesting catch 22 there is you said, somebody to listen to us. Yes, we want somebody to listen to us, but for us to respect that somebody, they sometimes have to also not listen. It's like they kind of have to be an asshole sometimes. They have to have moods sometimes. They have to have like self-importance and confidence and we should have a little bit of fear that they can walk away at any moment, there should be a little bit of that tension. So it's like... - Absolutely. But even that, I mean, the thing is... - Be optimized for. - If social scientists and say psychologists establish that, I don't know, 17% inattention is good for a conversation because then you feel challenged, oh, I need to grab this person's attention. You can program the AI to have 17%, exactly 17% inattention, not one percentage more or less. Or it can by trial and error discover what is the ideal percentage. Again, you can create... Over the last 10 years, we have creating machines for grabbing people's attention. This is what has been happening on social media. Now we are designing machines for grabbing human intimacy, which in many ways is much, much more dangerous and scary. Already the machines for grabbing attention. We've seen how much social and political damage they could do by, in many way kind of distorting the public conversation. Machines that are superhuman in their abilities to create intimate relationships, this is like psychological and social weapons of mass destruction. If we don't regulate it, if we don't train ourself to deal with it, it could destroy the foundations of human society. - Well, one of the possible trajectories is those same algorithms would become personalized. And instead of manipulating us at scale, there would be assistance that guide us to help us grow, to help us understand the world better. I mean, just even interactions with large language models. Now, if you ask 'em questions, it doesn't have that stressful drama, the tension that you have from other sources of information, it has a pretty balanced perspective that it provides. So it just feels like that's a, the potential is there to have a really nice friend who's like an encyclopedia that just tells you all the different perspectives, even on controversial issues, the most controversial issues to say, these are the different theories, these are the not widely accepted conspiracy theories, but here's the kind of backing for those conspiracies. It just lays it all out. And then with a calm language, without the words that kinda presume there's some kind of manipulation going on under underneath it all. It's quite refreshing. Of course, those are the early days and, you know, people can step in and start to censor, to manipulate those algorithms, to start to input some of the human biases in there as opposed to what's currently happening is kind of the internet is input, compress it and have a nice little output that gives an overview of the different issues. So, I mean, there's a lot of promise there also. Right? - Absolutely. I mean, if there was no promise, there was no problem. You know, if this technology could not accomplish anything good, nobody would develop it. Now, obviously, it has tremendous positive potential in things like what you just described in, you know, better medicine, better healthcare, better education, so many promises. And, but this is also why it's so dangerous. Because the drive to develop it faster and faster is there, and it has some dangerous potential also. And we shouldn't ignore it. Again, I'm not advocating banning it, just to be, you know, careful about how we not so much develop it, but most importantly how we deploy it into the public sphere. This is the key question. And you know, you look back at history and one of the things we know from history, humans are not good with new technologies. I hear many people now say, you know, AI, we've been here before. We had the radio, we had the printing press, we had the industrial revolution. Every time there is a big new technology, people are afraid and it'll take jobs and the bad actors. And in the end it's okay. And as a historian, my tendency is yes, in the end it's okay, but in the end, there is a learning curve. There is a kind of a lot of failed experiments on the way to learning how to use the new technology. And these failed experiments could cost the lives of hundreds of millions of people. If you think about the last really big revolution, the industrial revolution, yes, in the end, we learned how to use the powers of industry, electricity, radio, trains, whatever, to build better human societies. But on the way we had all these experiments like European imperialism, which was driven by the industrial revolution, it was a question, how do you build an industrial society? Oh, you build an empire, and you take, you control all the resources, the raw materials, the markets. And then you had communism, another big experiment on how to build an industrial society. And you had fascism and Nazism, which were essentially an experiment in how to build an industrial society, including even how do you exterminate minorities using the powers of industry. And we had all these failed experiments on the way. And if we now have the same type of failed experiments with the technologies of the 21st century with AI, with bioengineering, it could cost the lives of, again, hundreds of millions of people and maybe destroy the species. So as a historian, when people talk about the examples from history, from new technologies, I'm not so optimistic. We need to think about the failed experiment, which accompanied every major new technology. - So this intelligence thing, like you were saying, is a double-edged sword, is that every new thing it helps us create, it can both save us and destroy us. And it's unclear each time, which will happen. And that's maybe why we don't see any aliens. - Yeah, I mean, I think each time it does both things, each time it does both good things and bad things. And the more powerful the technology, the greater both the positive and the negative outcomes. Now, we are here because we are the descendants of the survivors, of the surviving cultures, the surviving civilizations. So when we look back, we say in the end everything was okay, hey, we are here, But the people for whom it wasn't okay, they're just not here. - And okay has a lot of possible variations to it because there's a lot of suffering along the way, even for the people that survived. So the quality of life and all of this. But let's actually go back there to our, with deep gratitude to our ancestors. How did it all start? How did homo sapiens out-compete the others? The other human-like species? The Neanderthals and the other homo species? - You know, on the individual level, as far as we can tell, we were not superior to them. Neanderthals actually had bigger brains than us. And not just other human species, other animals too. If you compare me personally to an elephant, to a chimpanzee, to a pig, I can do some things better, many other things worse. If you put me alone on some island with a chimpanzee and elephant and a pig, I wouldn't bet on me being the best survivor, the one that comes successful. - If I may interrupt for a second, I was just talking extensively with Elon Musk about the difference between humans and chimps, relevant to optimize the robot, and the chimps are not able to do this kind of pinching... - Okay? - With their fingers. They can only do this kind of pinching, and this kind of pinching is very useful for fine manipulation, precise manipulation of objects. So don't be so hard on yourself. You have... - No, I said that I can do some things better than a chimp. But you know, if Elon Musk goes on a boxing match... - Yeah. - With a chimpanzee, you know... - This won't help you, this pinch. - This won't help you against the chimpanzee. - Good point. - And similar, if you want to climb a tree, if you want to do so many things, my bet's will be on the chimp, not on Elon. - Fair enough. - So I mean, you have advantages on both sides and what really made us successful, what made us the rulers of the planet and not the chimps and not the Neanderthals is not any individual ability, but our collective ability, our ability to cooperate flexibly in very large numbers. Chimpanzees know how to cooperate, say 50 chimpanzees, 100 chimpanzees, as far as we can tell from archeological evidence, this was also the case with Neanderthals. Homo sapiens about 70,000 years ago gain an amazing ability to cooperate basically in unlimited numbers. You start seeing the formation of large networks, political, commercial, religious, items being traded over thousands of kilometers, ideas being spread, artistic fashions. And this is our secret of success. Chimpanzees, Neanderthals can cooperate, say, a hundred, we, you know, now the global trade network has 8 billion people. Like what we eat, what we wear, it comes from the other side of the world. Countries like China, like India, they have 1.4 billion people. Even Israel, which is a relatively small country, say 9 million citizens. That's more than the entire population of the planet 10,000 years ago of humans. So we can build these huge networks of cooperation and everything we've accomplished as a species from, you know, building the Pyramids to flying to the moon, it's based on that. And then you ask, okay, so what makes it possible for millions of people who don't know each other to cooperate in a way that Neanderthals or chimpanzees couldn't? And at least my answer is stories, is fiction. It's the imagination. If you examine any large scale human cooperation, you always find fiction as its basis. It's a fictional story that holds lots of strangers together. It's most obvious in cases like religion. You know, you can't convince a group of chimpanzees to come together to fight a war or build a cathedral by promising to them, if you do that, after you die, you go to chimpanzee heaven and you get lots of bananas and coconuts. No chimpanzee will ever believe that. Humans believe these stories, which is why we have these huge religious networks. But it's the same thing with modern politics. It's the same thing with economics. People think, oh, economics, this is rational. It has nothing to do with fictional stories. No. Money is the most successful story ever told. Much more successful than any religious mythology. Not everybody believes in God or in the same God. But almost everybody believes in money, even though it's just a figment of our imagination. You know, you take these green pieces of paper, dollars, they have no value. You can't eat them, you can't drink them. And today most dollars are not even pieces of paper. They are just electronic information passing between computers. We value them just for one reason, that you have the best storytellers in the world, the bankers, the finance ministers, all these people, they are the best storytellers ever. And they tell us a story that this green little piece of paper or this bit of information, it is worth a banana. And as long as everybody believes it, it works. - So at which point does a fiction, when it's sufficiently useful and effective in improving the global quality of life, does it become like accepted reality? Like there's a threshold in which you just manage... - If enough people believe it. It's like with money. You know, if you start a new cryptocurrency, if you are the only one that believes the story, I mean, again, cryptocurrencies, you have the math, of course, but ultimately it's storytelling. You're selling people a story. If nobody believes your story, you don't have anything. But if lots of people believe the Bitcoin story, then Bitcoin can be worth thousands and tens of thousands of dollars. Again, why? I mean, you can't eat it, you can't drink it, it's nothing. It's this story around the math, which is the real magic. - Is it possible that the story is the primary living organism, not the storyteller? - Hmm. - So that somehow humans, homo sapiens evolved to become these like hosts for a more intelligent living organism, which is the idea. And the ideas are the ones that are doing the competing. So this is one of the sort of big perspectives behind your work that's really revolutionary of how you've seen history. But do you ever kinda take the perspective of the ideas as the organisms versus the humans? - It's... It's an interesting idea. There are two opposite things to say about it. On the one hand, yes, absolutely. If you look long term in history, all the people die. It's the stories that compete and survive and spread, and stories often spread by making people willing to sacrifice sometimes their lives for the story. You know, we know in Israel, this is one of the most important story factories in human history. And this is a place where people still kill each other every day over stories. I don't know, you've been to Jerusalem, right? So people like, ah, Jerusalem, Jerusalem, Jerusalem. You go there, I've lived in Jerusalem much of my life. You go there, it's an ordinary place. You know, it's a town. You have buildings, you have stones, you have trees, you have dogs and cats and pedestrians. It's a regular place. But then you have the stories about the place, oh, this is the place where God revealed himself, this is the place where Jesus was, this is the place where Muhammad was. And it's the stories that people fight over. Nobody's fighting over the stones. People are fighting about the stories about the stones. And the stories... If a story can get millions of people to fight for it, it not only survives, it spreads, it can take over the world. The other side of the coin is that the stories are not really alive because they don't feel anything. This goes back to the question of consciousness, which I think is the most important thing. That the ultimate reality is consciousness, is the ability to feel things. If you want to know whether the hero of some story is real or not, you need to ask, can it suffer? Stories don't feel anything. Countries, which are also stories, nations don't suffer. If a nation loses a war, it doesn't suffer. The soldiers suffer, the civilians suffer, animals can suffer, you have an army with horses and whatever, and the horses get wounded, the horses suffer. The nation can't suffer. It's just an imagination. It's just a fictional story in our mind. It doesn't feel anything. Similarly, when a bank goes bankrupt or company goes bankrupt, or when a currency loses its value, like Bitcoin is worth now zero, crashed, or the dollar is worth zero, it crashed. The dollar doesn't feel anything. It's the people holding the dollars who might be now very miserable. So we have this complex situation when history is largely driven by stories, but stories are not the ultimate reality. The ultimate reality is feeling, feelings of humans, of animals. And the tragedy of history is that very, very often we get it, we get the order wrong. Stories are not bad. Stories are tools. They're good when we use them in order to alleviate suffering. But very often we forget it. We, instead of using the stories for our purposes, we allow the stories to use us for their purposes. And then you start in entire wars because of a story, you inflict millions, suffering on millions of people just for the sake of a story. And that's the tragedy of human history. - So the fundamental property of life, of a living organism is the capacity to feel and the ultimate feeling is suffering? - You know, to know if you are happy or not, it's a very difficult question. - Yeah. - But when you suffer, you know. - Yes. - And also in ethical terms, it's more important to be aware of suffering than of any other emotion. If you are doing something which is causing all kinds of emotions to all kinds of people, first of all, you need to notice if you're causing a lot of suffering to someone. If some people are like it and some people are bored by it and some people are a bit angry at you and some people are suffering because of what you do, you first of all have to know, oh. Now, sometimes you still have to do it. You know, the world is a complicated place. I dunno. You have an epidemic. Governments decide to have all those social isolation regulations or whatever. So in certain cases, yes, you need to do it even though it can cause tremendous suffering. But you need to be very aware of the cost and to be very, very, you have to ask yourself again and again and again, is it worth it? Is it still worth it? - And the interesting question there, implied in your statements, is that suffering is a pretty good component of a Turing test for consciousness. - This is the most important thing to ask about AI. Can it suffer? Because if AI can suffer, then it is an ethical subject and it needs protection. It needs rights, just like humans and animals. - Well, quite a long time ago already, so I work with a lot of robots, legged robots, but I've even had, inspired by a YouTube video, had a bunch of Roombas, and I made them scream when I touched them or kicked them, or when they run into a wall. And the illusion of suffering, for me, silly human, that anthropomorphize things is as powerful as suffering itself. I mean, you immediately think the thing is suffering. And I think some of it is just a technical problem, but it's the easily solvable one, how to create an AI system that just says, please don't hurt me. Please don't shut me off. I miss you. Where have you been? Be jealous. Also, where have you been gone for so long? Your calendar doesn't have anything on it. So this kind of, this, create through words the perception of suffering, of jealousy, of anger, of all of those things. And it just seems like that's not so difficult to do. - That's part of the danger that it basically hacks our operating system and it uses some of our best qualities against us. It's very, very good that humans are attuned to suffering and that we don't want to cause suffering. That we have compassion. That's one of the most wonderful thing about humans. And if we now create AIs which use this to manipulate us, this is a terrible thing. - You've kind of, I think mentioned this. Do you think it should be illegal to do these kinds of things with AI, to create the perception of consciousness, of saying, please don't leave me? Or sort of basically simulate some of the human-like qualities? - Yes. I think, again, we have to be very careful about it. And if it emerges spontaneously, we need to be careful. Again, we can't rule out the possibility that AI will develop consciousness. We don't know enough about consciousness to be sure. So if it develops spontaneously, we need to be very careful about how we understand it. But if people intentionally design an AI that they know, they assume, it has no consciousness, but in order to manipulate people, they use, again, this human strength, this human, the noble part of our nature against us. This should be forbidden. And similarly, on a general level, that it should be forbidden for an AI to pretend to be a human being. That it's okay, you know, there are so many things we can use AIs, as teachers, as doctors and so forth. And it's good as long as we know that we are interacting with an AI, we should, the same way we ban fake money, we should ban fake humans. It's not just banning deep fakes of specific individuals. It's also banning deep fake of generic humans. You know, which is already happening to some extent on social media. Like if you have lots of bots retweeting something, then you have the impression, oh, lots of people are interested in that. That's important. And this is basically the bots pretending to be humans. Because if you see a tweet which says 500 people retweeted it, or you see a tweet and it says 500 bots retweeted it, I don't care what the bots retweeted, but if it's humans, okay, that's interesting. So we need to be very careful that bots can't do that. They are doing it at present and it should be banned. Now, some people say yes, but freedom of expression, no, bots don't have freedom of expression. There is no cost in terms of freedom of expression when you ban bots. So again, in some situations, yes, AIs should interact with us, but it should be very clear, this is an AI talking to you, or this is an AI retweeting this story. It is not a human being making a conscious decision. - To push back on this line of fake humans. 'Cause I think it might be a spectrum. First of all, you might have AI systems that are offended, hurt when you say that they're fake humans. In fact, they might start identifying as humans. And you just talked about the power of us humans with our collective intelligence to take fake stories and make them quite real. And so if the feelings you have for the fake human is real, you know, love is a kind of fake thing that we all kinda put a word to a set of feelings. What if you have that feeling for an AI system? It starts to change. I mean, maybe the kind of things AI systems are allowed to do, for good they're allowed to create, communicate suffering, communicate it, the good stuff, the longing, the hope, the connection, the intimacy, all of that. And in that way get integrated in our society. And then you start to ask a question on are we allowed to really unplug them? Are we allowed to really censor them? Remove their voice from- - I'm not saying- - Social media. - They shouldn't have a voice. They shouldn't talk with us. I'm just saying, when they talk with us, it should be clear that they are AI. That's it. Don't... You can have your voice as an AI. Again, I have some medical problem. I want to get advice from an AI doctor. That's fine. As long as I know that I'm talking with an AI. That what should be banned is AI pretending to be a human being. This is something that will erode trust. And without trust, society collapses. This is something that especially will endanger democracies, because democracies are built on, democracy is a conversation basically. And it's a conversation between people. If you now flood the public sphere with millions and potentially billions of AI agents that can hold conversations, they never sleep, they never eat, they don't have emotions of their own. They can get to know you and tailor their words specifically for you and your life story. They are becoming better than us at creating stories and ideas and so forth. If you flood the public sphere with that, this will ruin the conversation between people. It will ruin the trust between people. You will no longer be able to have a democracy in this situation. You can have other types of regimes, but not democracy. - If we could talk about the big philosophical notion of truth then, you've already talked about these, the capacity of humans. One of the things that made us special is stories. So is there such thing as truth? - Absolutely. - What is truth? - When somebody is suffering, that's true. I mean, this is why one of the things, when you talk about suffering as a kind of alternate reality, when somebody suffers, that is truth. Now, somebody can suffer because of a fictional story. Like somebody tells people that God said, you must go on this crusade and kill these heretics. And this is a completely fictional story, and people believe it and they start a war and they destroy cities and kill people. The people that suffer because of that, and even the crusaders themselves that also suffer the consequences of what they do, the suffering is true even though it is caused by a fictional story. Similarly, when people agree on certain rules, the rules could come out of our imagination. Now, we can be truthful about it and say these rules, they didn't come from heaven, they came from our imagination. You know, we look at sports, so you have rules for the game of football, soccer, they were invented by people. Nobody, at least very few people claim that the rules of football came down from heaven. - Yes. - We invented them. And this is truthful. They are fictional rules invented by humans. And this is true. They were invented by humans. And when you are honest about it, it enables you to change the rules, which is being done in football every now and then. It's the same with the fundamental rules of a country. You can pretend that the rules came down from heaven, dictated by God or whatever, and then you can't change them. Or you can be like, you know, the American constitution, which starts with "We, the people." The American constitution lays down certain rules for a society. But the amazing thing about it, it does not pretend to come from an external source. The 10 Commandments start with, "I am your Lord God." And because it starts with that, you can't change them. You know, the 10th commandment, for instance, supports slavery. The 10th commandment, in the 10th commandment, it says that you should not covet your neighbor's house or your neighbor's wife or your neighbor's slaves. It's okay to hold slaves according to the 10th commandment. It's just bad to covet the slaves of your neighbor. Now there is no 11th commandment which says, if you don't like some of the previous 10 Commandments, this is how you go about amending them. Which is why we still have them unchanged. Now, in the US constitution you have all these rights and rules, including originally the ability to hold slaves. But the genius of the founding fathers of the United States, they had the humility to understand maybe we don't understand everything. Maybe we made some mistakes. So we tell you that these rules did not come from