Do you have to look at whole systems? I've never done anything like that. I don't know much about it. The people who I've talked to who do work on it say amazing things can happen. And a bit of a brain grown in a dish is capable of experiencing some kind of feelings or even memories of its former brain. Again, I have a feeling that until we understand how to control the electrical fields that control development, we're not going to understand how to turn an organoid into a real functional system. But how do we get that understanding? It's so incredibly difficult. I mean, you would have to, I mean, one promising direction, I'd love to get your opinion on this. I don't know if you're familiar with the work of DeepMind and AlphaFold with protein folding and so on. Do you think it's possible that that will give us some breakthroughs in biology, trying to basically simulate and model the behavior of trivial biological systems as they become complex biological systems? I'm sure it will. The interesting thing to me about protein folding is that for a long time, my understanding, this is not what I work on, so I may have got this wrong, but my understanding is that you take the sequence of a protein and you try to fold it. And there are multiple ways in which it can fold and to come up with the correct confirmation is not a very easy thing because you're doing it from first principles from a string of letters, which specify the string of amino acids. But what actually happens is when a protein is coming out of a ribosome, it's coming out of a charged tunnel and it's in a very specific environment, which is going to force this to go there now and then this one to go there and this one to come like that. And so you're forcing a specific conformational set of changes onto it as it comes out of the ribosome. So by the time it's fully emerged, it's already got its shape. And that shape depended on the immediate environment that it was emerging into, one letter, one amino acid at a time. And I don't think that the field was looking at it that way. And if that's correct, then that's very characteristic of science, which is to say it asks very often the wrong question and then does really amazingly sophisticated analyses on something having never thought to actually think, well, what is biology doing? And biology is giving you a charged electrical environment that forces you to be this way. Now, did DeepMind come up through patterns with some answer that was like that? I've got absolutely no idea. It ought to be possible to deduce that from the shapes of proteins. It would require much greater skill than the human mind has. But the human mind is capable of saying, well, hang on, let's look at this exit tunnel and try and work out what shape is this protein going to take and we can figure that out. That's really interesting about the exit tunnel. But like sometimes we get lucky and just like in science, the simplified view or the static view will actually solve the problem for us. So in this case, it's very possible that the sequence of letters has a unique mapping to our structure without considering how it unraveled, so without considering the tunnel. And so that seems to be the case in this situation where the cool thing about proteins, all the different shapes they can possibly take, it actually seems to take very specific, unique shapes given the sequence. That's forced on you by an exit tunnel. So the problem is actually much simpler than you thought. And then there's a whole army of proteins which change the conformational state, chaperone proteins. And they're only used when there's some, presumably, issue with how it came out of the exit tunnel and you want to do it differently to that. So very often the chaperone proteins will go there and will influence the way in which it falls. So there's two ways of doing it. Either you can look at the structures and the sequences of all the proteins and you can apply an immense mind to it and figure out what the patterns are and figure out what happened, or you can look at the actual situation where it is and say, well, hang on, it was actually quite simple. It's got a charged environment and then it's forced to come out this way. And then the question will be, well, do different ribosomes have different charged environments? What happens if a chaperone, you know, you're asking a different set of questions to come to the same answer in a way which is telling you a much simpler story and explains why it is, rather than saying it could be, you know, this is one in a billion different possible conformational states that this protein could have. You're saying, well, it has this one because that was the only one it could take given its setting. Well, yeah. I mean, currently humans are very good at that kind of first principles thinking, stepping back. But I think AI is really good at, you know, collect a huge amount of data and a huge amount of data of observation of planets and figure out that Earth is not at the center of the universe, that there's actually a sun, we're orbiting the sun. But then you can, as a human being, ask, well, how do solar systems come to be? What are the different forces that are required to make this kind of pattern emerge? And then you start to invent things like gravity. I mean, obviously. Is it an invention? I mixed up the ordering of gravity wasn't considered as a thing that connects planets, but we are able to think about those big picture things as human beings. AI is just very good to infer simple models from a huge amount of data. And the question is with biology, you know, we kind of go back and forth how we solve biology. Listen, protein folding was thought to be impossible to solve. And there's a lot of brilliant PhD students that worked one protein at a time trying to figure out the structure. And the fact that I was able to do that. Oh, I'm not knocking it at all, but I think that people have been asking the wrong question. But then as the people start to ask better and bigger questions, the AI kind of enters the chat and says, I'll help you out with that. Can I give you another example of my own work? Um, the risk of getting a disease as we get older, there are genetic aspects to it. You know, if you spend your whole life overeating and smoking and whatever, that's a whole separate question. But there's a genetic side to the risk. And we know a few genes that increase your risk of certain things. And for probably 20 years now, people have been doing what's called GWAS, which is genome wide association studies. So you effectively scan the entire genome for any single nucleotide polymorphisms, which is say a single letter change in one place that has a higher association of being linked with a particular disease or not. And you can come up with thousands of these things across the genome. And if you add them all up and try and say, well, so do they add up to explain the known genetic risk of this disease? And the known genetic risk often comes from twin studies. And you can say that if this twin gets epilepsy, there's a 40 or 50% risk that the other twin, identical twin, will also get epilepsy. Therefore, the genetic factor is about 50%. And so the gene similarities that you see should account for 50% of that known risk. Very often it accounts for less than a 10th of the known risk. And there's two possible explanations. And there's one which people tend to do, which is to say, ah, well, we don't have enough statistical power. If we, maybe there's a million, we've only found a thousand of them. But if we find the other million, they're weakly related, but there's a huge number of them. And so we'll account for that whole risk. Maybe there's a billion of them, for instance. So that's one way. The other way is to say, well, hang on a minute, you're missing a system here. That system is the mitochondrial DNA, which people tend to dismiss because it's small and it's not, it doesn't change very much. But a few single letter changes in that mitochondrial DNA, it controls some really basic processes. It controls not only all the energy that we need to live and to move around and do everything we do, but also biosynthesis to make the new building blocks to make new cells. And cancer cells very often kind of take over the mitochondria and rewire them so that instead of using them for making energy, they're effectively using them as precursors for the building blocks for biosynthesis. You need to make new amino acids, new nucleotides for DNA. You want to make new lipids to make your membranes and so on. So they kind of rewire metabolism. Now, the problem is that we've got all these interactions between mitochondrial DNA and the genes in the nucleus that are overlooked completely because people throw away, literally throw away the mitochondrial genes. And we can see in fruit flies that they interact and produce big differences in risk. So you can set AI onto this question of exactly how many of these base changes there are. That's just one possible solution that maybe there are a million of them and it does account for the greatest part of the risk. Or the other one is they aren't, it's just not there. Actually, the risk lies in something you weren't even looking at. And this is where human intuition is very important. And just this feeling that, well, I'm working on this and I think it's important and I'm bloody minded about it. And in the end, some people are right. It turns out that it was important. Can you get AI to do that, to be bloody minded? And that, hang on a minute, you might be missing a whole other system here that's much bigger. That's the moment of discovery, of scientific revolution. I'm giving up on saying AI can't do something. I've said it enough times about enough things. I think there's been a lot of progress. And instead, I'm excited by the possibility of AI helping humans. But at the same time, just like I said, we seem to dismiss the power of humans. Yes, yes. Like we're so limited in so many ways that we kind of, in what we feel like dumb ways, like we're not strong, we're kind of, our attention, our memory is limited. Our ability to focus on things is limited. in our own perception of what limit it is. But that actually, there's an incredible computer behind the whole thing that makes this whole system work. Our ability to interact with the environment, to reason about the environment. There's magic there. And I'm hopeful that AI can capture some of that same magic. But that magic is not gonna look like Deep Blue playing chess. It's going to be more interesting. But I don't think it's gonna look like pattern finding either. I mean, that's essentially what you're telling me. It does very well at the moment. And my point is, it works very well where you're looking for the right pattern. But we are storytelling animals. And a hypothesis is a story. It's a testable story. But a new hypothesis is a leap into the unknown. And it's a new story, basically. And it says, this leads to this, leads to that. It's a causal set of storytelling. It's also possible that the leap into the unknown has a pattern of its own. Yes, it is. And it's possible that it's learnable. I'm sure it is. There's a nice book by Arthur Koestler on the nature of creativity. And he likens it to a joke where the punchline goes off in a completely unexpected direction and says that this is the basis of human creativity. Some creative switch of direction to an unexpected place is similar to a joke. I'm not saying that's how it works, but it's a nice idea and there must be some truth in it. And it's one of these, most of the stories we tell are probably the wrong story and probably going nowhere and probably not helpful. And we definitely don't do as well at seeing patterns in things. But some of the most enjoyable human aspects is finding a new story that goes to an unexpected place. And these are all aspects of what being human means to me. And maybe these are all things that AI figures out for itself, or maybe they're just aspects. But I just have the feeling sometimes that the people who are trying to understand what we are like, if we wish to craft an AI system which is somehow human-like, that we don't have a firm enough grasp of what humans really are like in terms of how we are built. But we get a better, better understanding of that. I agree with you completely.