But there's degrees of consciousness and so on, but people are definitely much more uncomfortable saying a toaster can be conscious than a dog. And there's still a deep connection, you could say our relationship with the dog has more to do with anthropomorphism, like we kind of project a human being onto it. Maybe. We can do the same damn thing with a toaster. Yes, but you can look into the dog's eyes and you can see that it's sad, that it's delighted to see you again. I don't have a dog, by the way, it's not that I'm a dog person. Dogs are actually incredibly good at using their eyes, they do just that. They are. Now, I don't imagine that a dog is remotely as close to being intelligent as an AI intelligence, but it's certainly capable of communicating emotionally with us. But here's what I would venture to say, we tend to think because AI plays chess well and is able to fold proteins now well, that it's intelligent. I would argue that in order to communicate with humans, in order to have emotional intelligence, it actually requires another order of magnitude of intelligence. It's not easy to be flawed. Solving a mathematical puzzle is not the same as the full complexity of human to human interaction. That's actually, we humans just take for granted the things we're really good at. Non-stop people tell me how shitty people are at driving. No, humans are incredible at driving. Bipedal walking, walking, object manipulation, we're incredible at this. And so people tend to- Discount the things we all just take for granted. And one of those things that they discount is our ability, the dance of conversation and interaction with each other. The ability to morph ideas together, the ability to get angry at each other and then to miss each other, to create a tension that makes life fun and difficult and challenging in a way that's meaningful. That is a skill that's learned and AI would need to solve that problem. In some sense, what you're saying is AI cannot become meaningfully emotional, let's say, until it experiences some kind of internal conflict that is unable to reconcile these various aspects of reality or its reality with a decision to make. And then it feels sad, necessarily, because it doesn't know what to do. And I certainly can't dispute that. That may very well be how it works. I think the only way to find out is to do it. To build it, yeah. And leave it to the philosophers if it actually feels sad or not. The point is, the robot will be sitting there alone, having an internal conflict, an existential crisis, and that's required for it to have a deep, meaningful connection with another human being. Now, does it actually feel that? I don't know. But I'd like to throw something else at you, which troubles me on reading it. Noah Harari's book, 21 Lessons for the 21st Century, and he's written about this kind of thing on various occasions. He sees biochemistry as an algorithm, and then AI will necessarily be able to hack that algorithm and do it better than humans. So there will be AI better at writing music that we appreciate than Mozart ever could or writing better than Shakespeare ever did and so on, because biochemistry is algorithmic and all you need to do is figure out which bits of the algorithm to play to make us feel good or bad or appreciate things. As a biochemist, I find that argument close to irrefutable and not very enjoyable. I don't like the sound of it. That's just my reaction as a human being. You might like the sound of it because that says that AI is capable of the same kind of emotional feelings about the world as we are, because the whole thing is an algorithm and you can program an algorithm and there you are. He then has a peculiar final chapter where he talks about consciousness in rather separate terms, and he's talking about meditating and so on and getting in touch with his inner conscious. I don't meditate. I don't know anything about that, but he wrote in very different terms about it as if somehow it's a way out of the algorithm. Now it seems to me that consciousness in that sense is capable of scuppering the algorithm. In terms of the biochemical feedback loops and so on, it is undoubtedly algorithmic, but in terms of what we decide to do, it can be much more based on an emotion. We can just think, I don't care. I can't resolve this complex situation. I'm going to do that. That can be based on, in effect, a different currency, which is the currency of feelings and something where we don't have very much personal control over. And then it comes back around to you and what are you trying to get at with AI? Do we need to have some system which is capable of overriding a rational decision which cannot be made because there's too much conflicting information by effectively an emotional judgmental decision that just says, do this and see what happens. That's what consciousness is really doing in my view. Yeah, and the question is whether it's a different process or just a higher level process. I might, you know, the idea that biochemistry is an algorithm is to me an oversimplistic view. There's a lot of things that the moment you say it, it's irrefutable, but it simplifies. I'm sure it's an extremely complex system. And in the process, loses something fundamental. So, for example, calling a universe an information processing system, sure, yes, you could make that. It's a computer that's performing computations, but you're missing the process of the entropy somehow leading to pockets of complexity that creates these beautiful artifacts that are incredibly complex and they're like machines. And then those machines are through the process of evolution are constructing even further complexity. Like, in calling the universe an information processing machine, you're missing those little local pockets and how difficult it is to create them. So, the question to me is if biochemistry is an algorithm, how difficult is it to create a software system that runs the human body, which I think is incorrect. I think that is going to take so long, I can't, I mean, that's going to be centuries from now to be able to reconstruct the human. Now, what I would venture to say to get some of the magic of a human being, what we're saying with the emotions and the interactions and like a dog makes a smile and joyful and all those kinds of things, that will come much sooner. But that doesn't require us to reverse engineer the algorithm of biochemistry. Yes, but the toaster is making you happy. Yes. It's not about whether you make the toaster happy. No, it has to be. It has to be. It has to be. The toaster has to be able to leave me happy. Yes, but it's the toaster is the AI in this case, is a very intelligent. Yeah, the toaster has to be able to be unhappy and leave me. That's essential. Yeah. That's essential for my being able to miss the toaster. If the toaster is just my servant, that's not or a provider of like services, like tells me the weather makes toast, that's not going to deep connection. It has to have internal conflict. You write about life and death. It has to be able to be conscious of its mortality and the finiteness of its existence. And that life is temporary and therefore needs to be more selective. One of the most moving moments in the movies from when I was a boy was the unplugging of Howl in 2001, where that was the death of a sentient being and Howl knew it. So I think we all kind of know that a sufficiently intelligent being is going to have some form of consciousness, but whether it would be like biological consciousness, I just don't know. And if you're thinking about how do we bring together, I mean, obviously we're going to interact more closely with AI, but is a dog really like a toaster or is there really some kind of difference there? You were talking about biochemistry is algorithmic, but it's not single algorithm and it's very complex. Of course it is. There are, again, conflicts in the circuits of biochemistry, but I have a feeling that the level of complexity of the total biochemical system at the level of a single cell is less complex than the level of neural networking in the human brain or in an AI. Well, I guess I assumed that we were including the brain in the biochemistry algorithm because you have to... I would see that as a higher level of organization of neural networks. They're all using the same biochemical wiring within themselves. Yeah. But the human brain is not just neurons. It's the immune system. It's the whole package. I mean, to have a biochemical algorithm that runs a intelligent biological system, you have to include the whole damn thing. And it's pretty fascinating that it comes from an embryo. The whole... I mean, oh boy. I mean, if you can... What is a human being? Because it's... But if you look at... It's just some code and then you build... And then that... So it's DNA doesn't just tell you what to build, but how to build it. I mean, the thing is impressive. And the question is how difficult is it to reverse engineer the whole shebang? Very difficult. I would say it's... I don't want to say impossible, but it's much easier to build a human than to reverse engineer, to build like a fake human, human-like thing, than to reverse engineer the entirety of the process of the evolution of a reptile. I'm not sure if we are capable of reverse engineering the whole thing, if the human mind is capable of doing that. I mean, I wouldn't be a biologist if I wasn't trying, but I know I can't understand the whole problem. I'm just trying to understand the rudimentary outlines of the problem. There's another aspect, though. You're talking about developing from a single cell to the human mind and all the part system, subsystems that are part of an immune system and so on. This is something that you'll talk about, I imagine, with Michael Levin, but so little is known about, you talk about reverse engineering, so little is known about the developmental pathways that go from a genome to going to a fully wired organism. And a lot of it seems to depend on the same electrical interactions that I was talking about happening at the level of single cells and its interaction with the environment. There's a whole electrical field side to biology that is not yet written into any of the textbooks, which is about how does an embryo develop into, or a single cell develop into these complex systems? What defines the head? What defines the immune system? What defines the brain and so on? That really is written in a language that we're only just beginning to understand. And frankly, biologists, most biologists are still very reluctant to even get themselves tangled up in questions like electrical fields influencing development. It seems like mumbo jumbo to a lot of biologists, and it should not be because this is the 21st century biology. This is where it's going. But we're not gonna reverse engineer a human being or the mind or any of these subsystems until we understand how this developmental processes work, how electricity in biology really works. And if it is linked with feelings and with consciousness and so on, that's the, I mean, in the meantime, we have to try, but I think that's where the answer lies. So you think it's possible that the key to things like consciousness are some of the more tricky aspects of cognition might lie in that early development, the interaction of electricity and biology. Electrical fields. But we already know the EEG and so on is telling us a lot about brain function, but we don't know which cells, which parts of a neural network is giving rise to the EEG. We don't know the basics. The assumption is, I mean, we know it's neural networks. We know it's multiple cells, hundreds or thousands of cells involved in it. And we assume that it's to do with depolarization during action potentials and so on. But the mitochondria, which are in there, have much more membranes than the plasma membrane of the neuron. And there's a much greater membrane potential. And it's formed in parallel, very often parallel crystae, which are capable of reinforcing a field and generating fields over longer distances. And nobody knows if that plays a role in consciousness or not. There's reasons to argue that it could, but frankly, we simply do not know. And it's not taken into consideration. You look at the structure of the mitochondrial membranes in the brains of simple things like Drosophila, the fruit fly, and they have amazing structures. You can see lots of little rectangular things all lined up in amazing patterns. What are they doing? Why are they like that? We haven't the first clue. What do you think about organoids and brain organoids? And like, so in a lab trying to study the development of these in the Petri dish development of organs, do you think that's promising?