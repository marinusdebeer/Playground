{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a youtube URL the following will download transcript then summarize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import openai\n",
    "import os\n",
    "import whisper\n",
    "from dotenv import load_dotenv\n",
    "import youtube_dl\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import shutil\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# video_url = 'https://www.youtube.com/watch?v=SNgoul4vyDM'\n",
    "# summary_title = \"ufo_hearing_whisper_transcribe_audio_gpt_4\"\n",
    "\n",
    "video_url = 'https://www.youtube.com/watch?v=Qwbp9T-WS-I'\n",
    "summary_title = \"b1m_solved_urban_sprawl\"\n",
    "\n",
    "video_id = video_url.split('=')[1]\n",
    "task = \"Please turn the following into an article including all the key ideas: \\n\"\n",
    "\n",
    "models = ['gpt-3.5-turbo', 'gpt-4']\n",
    "USE = 1\n",
    "TRANSCRIBE = True\n",
    "LOCAL_WHISPER = False\n",
    "tokens_cost = 0\n",
    "if USE == 0:\n",
    "    chunk_size = 2300\n",
    "    input_cost = 0.0015/1000\n",
    "    output_cost = 0.002/1000\n",
    "else:\n",
    "    chunk_size = 4000\n",
    "    input_cost = 0.03/1000\n",
    "    output_cost = 0.06/1000\n",
    "\n",
    "audio_cost_per_second = 0.006/60\n",
    "audio_cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_from_youtube(video_url, output_path, file_name=\"audio.mp4\"):\n",
    "    \n",
    "    yt = YouTube(video_url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    audio_stream.download(output_path, filename=file_name)\n",
    "    print(\"Audio download completed!\")\n",
    "    \n",
    "    \n",
    "    return output_path + \"/\" + file_name\n",
    "\n",
    "def split_audio_into_chunks(audio_path, output_folder, chunk_duration=900):\n",
    "    audio = AudioSegment.from_file(audio_path, format=\"mp4\")\n",
    "    audio_duration_ms = len(audio)\n",
    "    \n",
    "    for start_time_ms in range(0, audio_duration_ms, chunk_duration * 1000):\n",
    "        end_time_ms = start_time_ms + (chunk_duration * 1000)\n",
    "        chunk = audio[start_time_ms:end_time_ms]\n",
    "        location = f\"{output_folder}/audio_chunks\"\n",
    "        if not os.path.exists(location):\n",
    "            os.makedirs(location)\n",
    "        output_file = f\"{output_folder}/audio_chunks/chunk_{start_time_ms//1000}.mp4\"\n",
    "        chunk.export(output_file, format=\"mp4\")\n",
    "\n",
    "\n",
    "def get_video_title(url):\n",
    "    with youtube_dl.YoutubeDL({}) as ydl:\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        return info_dict.get('title', None)\n",
    "\n",
    "\n",
    "def summarize(input, model=models[USE]):\n",
    "    global input_tokens, output_tokens, input_cost, output_cost, tokens_cost\n",
    "  \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=input)\n",
    "\n",
    "    input_tokens += completion.usage.prompt_tokens\n",
    "    output_tokens += completion.usage.completion_tokens\n",
    "\n",
    "    tokens_cost = input_tokens*input_cost + output_tokens*output_cost\n",
    "    print(f\"Tokens thus far: {input_tokens + output_tokens} with a cost of ${round(tokens_cost, 4)}\")\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    return reply_content\n",
    "\n",
    "\n",
    "def create_directory(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "\n",
    "def download_transcript(video_id):\n",
    "    video_id = video_id.split('=')[-1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "    with open(f\"{summary_title}/transcript.txt\", \"w\") as file:\n",
    "        for line in transcript:\n",
    "            file.write(line['text'] + '\\n')\n",
    "\n",
    "\n",
    "def chunk_transcript_sentences(file_name, chunk_size, summary_title):\n",
    "    # Open and read the file\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read().replace('\\n', ' ')\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split('(?<=[.!?]) +', text)\n",
    "\n",
    "    chunks, chunk = [], []\n",
    "    current_chunk_size = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split(' ')\n",
    "        sentence_length = len(sentence_words)\n",
    "\n",
    "        # If adding the next sentence doesn't exceed the chunk size, add it to the current chunk\n",
    "        if current_chunk_size + sentence_length <= chunk_size:\n",
    "            chunk.append(sentence)\n",
    "            current_chunk_size += sentence_length\n",
    "        else:\n",
    "            # Otherwise, finish the current chunk and start a new one\n",
    "            chunks.append(' '.join(chunk))\n",
    "            chunk = [sentence]\n",
    "            current_chunk_size = sentence_length\n",
    "\n",
    "    # Add the last chunk if it's non-empty\n",
    "    if chunk:\n",
    "        chunks.append(' '.join(chunk))\n",
    "\n",
    "    create_directory(f\"{summary_title}/chunks\")\n",
    "\n",
    "    # Write each chunk to a file\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(f'{summary_title}/chunks/chunk{i}.txt', 'w') as file:\n",
    "            file.write(chunk)\n",
    "\n",
    "\n",
    "def chunk_transcript(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read().replace('\\n', ' ')\n",
    "    words = text.split(' ')\n",
    "    chunks = [words[i:i + chunk_size]\n",
    "              for i in range(0, len(words), chunk_size)]\n",
    "    create_directory(f\"{summary_title}/chunks\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(f'{summary_title}/chunks/chunk{i}.txt', 'w') as file:\n",
    "            if chunk[-1] != '.':\n",
    "                chunk[-1] += '.'\n",
    "            file.write(' '.join(chunk))\n",
    "\n",
    "\n",
    "def get_sorted_files_by_date(directory):\n",
    "    file_list = os.listdir(directory)\n",
    "    files_with_mtime = [(file, os.path.getmtime(\n",
    "        os.path.join(directory, file))) for file in file_list]\n",
    "    sorted_files = sorted(files_with_mtime, key=lambda x: x[1])\n",
    "    sorted_filenames = [file[0] for file in sorted_files]\n",
    "    return sorted_filenames\n",
    "\n",
    "\n",
    "def read_text_from_files(directory_path):\n",
    "    text_array = []\n",
    "    files = get_sorted_files_by_date(directory_path)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                text_array.append(file.read())\n",
    "    return text_array\n",
    "\n",
    "\n",
    "def read_and_join_text_from_files(directory_path):\n",
    "    joined_text = \"\"\n",
    "    files = get_sorted_files_by_date(directory_path)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                joined_text += file.read() + \"\\n\"\n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(summary_title):\n",
    "  shutil.rmtree(summary_title)\n",
    "create_directory(summary_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download audio then transcribe using openai whisper api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio download completed!\n"
     ]
    }
   ],
   "source": [
    "if TRANSCRIBE:\n",
    "    audio_path = download_audio_from_youtube(video_url, summary_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio_duration: 1016198ms\n",
      "audio file size: 6197221\n",
      "Total audio cost: $ 0.4064\n"
     ]
    }
   ],
   "source": [
    "if TRANSCRIBE:\n",
    "    if os.path.exists(f\"{summary_title}/transcript.txt\"):\n",
    "        os.remove(f\"{summary_title}/transcript.txt\")\n",
    "    if LOCAL_WHISPER:\n",
    "        model = whisper.load_model(\"small\")\n",
    "        transcript = model.transcribe(f\"{summary_title}/audio.mp4\")[\"text\"]\n",
    "        with open(f\"{summary_title}/transcript.txt\", \"w\") as f:\n",
    "            f.write(transcript)\n",
    "    else:\n",
    "        global audio_cost\n",
    "        audio = AudioSegment.from_file(f\"{summary_title}/audio.mp4\", format=\"mp4\")\n",
    "        audio_duration_ms = len(audio)\n",
    "        audio_cost += audio_duration_ms // 1000 * audio_cost_per_second\n",
    "        print(f\"Audio_duration: {audio_duration_ms}ms\")\n",
    "        audio_size = os.path.getsize(f\"{summary_title}/audio.mp4\");\n",
    "        print(f\"audio file size: {audio_size}\")\n",
    "        if audio_size > 25_000_000:\n",
    "            split_audio_into_chunks(audio, summary_title, chunk_duration=1200)\n",
    "            files = get_sorted_files_by_date(summary_title+\"/audio_chunks\")\n",
    "            print(f\"Chunks to transcribe: {files}\")\n",
    "            for file in files:\n",
    "                print(f\"Transcribing {file}\")\n",
    "                file = open(summary_title + \"/audio_chunks/\" + file, \"rb\")\n",
    "                transcript = openai.Audio.transcribe(\"whisper-1\", file).text\n",
    "                with open(f\"{summary_title}/transcript.txt\", \"a\") as f:\n",
    "                    f.write(transcript)\n",
    "                    f.close()\n",
    "                file.close()\n",
    "        else:\n",
    "            file = open(summary_title + \"/\" + \"audio.mp4\", \"rb\")\n",
    "            transcript = openai.Audio.transcribe(\"whisper-1\", file).text\n",
    "            with open(f\"{summary_title}/transcript.txt\", \"a\") as f:\n",
    "                f.write(transcript)\n",
    "                f.close()\n",
    "            file.close()\n",
    "        print(\"Total audio cost: $\", round(audio_cost, 4))\n",
    "else:\n",
    "    download_transcript(video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunkify the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(summary_title+\"/chunks\"):\n",
    "    shutil.rmtree(summary_title+\"/chunks\")\n",
    "create_directory(summary_title+\"/chunks\")\n",
    "chunk_transcript_sentences(f'{summary_title}/transcript.txt', chunk_size, summary_title)\n",
    "# chunk_transcript(f'{summary_title}/transcript.txt')\n",
    "data = read_text_from_files(f\"{summary_title}/chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing 1 articles\n",
      "Tokens thus far: 3735 with a cost of $0.1335\n",
      "Total cost so far is: $0.133 tokens and $0.40640000000000004 audio\n"
     ]
    }
   ],
   "source": [
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "tokens_cost = 0\n",
    "\n",
    "data = read_text_from_files(f\"{summary_title}/chunks\")\n",
    "if os.path.exists(summary_title+\"/summaries\"):\n",
    "    shutil.rmtree(summary_title+\"/summaries\")\n",
    "create_directory(f\"{summary_title}/summaries\")\n",
    "\n",
    "if os.path.exists(summary_title+\"/instructions\"):\n",
    "    shutil.rmtree(summary_title+\"/instructions\")\n",
    "create_directory(f\"{summary_title}/instructions\")\n",
    "\n",
    "if os.path.exists(summary_title+\"/system\"):\n",
    "    shutil.rmtree(summary_title+\"/system\")\n",
    "create_directory(f\"{summary_title}/system\")\n",
    "\n",
    "print(f\"Summarizing {len(data)} articles\")\n",
    "multiple_summaries = len(data) > 1\n",
    "\n",
    "for i in range(len(data)):\n",
    "    messages = []\n",
    "    if i > 1:\n",
    "        with open(f\"{summary_title}/summaries/summary{i-2}.txt\", \"r\") as f:\n",
    "            sum1 = f.read()\n",
    "        with open(f\"{summary_title}/summaries/summary{i-1}.txt\", \"r\") as f:\n",
    "            sum2 = f.read()\n",
    "\n",
    "        messages.append(\n",
    "            {\"role\": \"user\", \"content\": \"Summarize the following:\\n\" + sum1 + '\\n' + sum2})\n",
    "        system_message = summarize(messages)\n",
    "\n",
    "        system_message = \"Always only provide a detailed summary of the input. Don't answer questions or complete the text. The following is the context to keep in mind: \\n\" + system_message\n",
    "        with open(f\"{summary_title}/system/system{i}.txt\", \"w\") as f:\n",
    "            f.write(system_message)\n",
    "        messages = []\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    elif i > 0:\n",
    "        with open(f\"{summary_title}/summaries/summary{i-1}.txt\", \"r\") as f:\n",
    "            system_message = \"Always only provide a detailed summary of the input. Don't answer questions or complete the text. The following is the context to keep in mind: \\n\" + f.read()\n",
    "            messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": task + data[i]})\n",
    "\n",
    "    with open(f\"{summary_title}/instructions/instruction_{i}.txt\", \"a\") as file:\n",
    "        for msg in messages:\n",
    "            file.write(msg[\"role\"] + \":\\n\")\n",
    "            file.write(msg[\"content\"] + \"\\n\")\n",
    "    # print(f\"Summarizing article {i} with {len(instruction.split(' '))} words\")\n",
    "\n",
    "    response = summarize(messages)\n",
    "    with open(f\"{summary_title}/summaries/summary{i}.txt\", \"w\") as f:\n",
    "        f.write(response)\n",
    "print(f\"Total cost so far is: ${round(tokens_cost, 3)} tokens and ${audio_cost} audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join summaries together then summarize them altogether using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = f'{summary_title}/summaries'\n",
    "joined_summaries = read_and_join_text_from_files(directory_path)\n",
    "files = get_sorted_files_by_date(directory_path)\n",
    "multiple_summaries = len(files) > 1\n",
    "with open(f'{summary_title}/summaries/joined_summaries.txt', 'w') as file:\n",
    "    file.write(joined_summaries)\n",
    "if multiple_summaries:\n",
    "    print(f\"Summarizing joined summaries with {len(joined_summaries.split(' '))} words\")\n",
    "    messages = [{\"role\": \"user\", \"content\": \"Make the following summaries flow as one long and detailed article: \\n\" + joined_summaries.rstrip()}]\n",
    "    with open(f\"{summary_title}/instructions/instruction.txt\", \"a\") as f:\n",
    "      for message in messages:\n",
    "        f.write(message[\"content\"] + \"\\n\")\n",
    "\n",
    "    sum = summarize(input=messages, model=\"gpt-4\")\n",
    "else:\n",
    "    sum = joined_summaries\n",
    "with open(f\"{summary_title}/summary.txt\", \"w\") as f:\n",
    "    f.write(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# voice_id = \"Matthew\"\n",
    "# voice_id = \"Ruth\"\n",
    "voice_id = \"Stephen\"\n",
    "output_format = \"mp3\"\n",
    "import pygame\n",
    "\n",
    "if os.path.exists(summary_title+\"/audio\"):\n",
    "    shutil.rmtree(summary_title+\"/audio\")\n",
    "create_directory(f\"{summary_title}/audio\")\n",
    "\n",
    "# Create an Amazon Polly client\n",
    "polly_client = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"polly_access_key_id\"),\n",
    "    aws_secret_access_key=os.getenv(\"polly_secret_key\"),\n",
    "    region_name='ca-central-1').client('polly')\n",
    "\n",
    "def generate_audio(input, count):\n",
    "  start_time = time.time()\n",
    "  audio = polly_client.synthesize_speech(\n",
    "      Text=input,\n",
    "      VoiceId=voice_id,\n",
    "      OutputFormat=output_format,\n",
    "      Engine=\"neural\"\n",
    "      )\n",
    "  save_audio(audio, count)\n",
    "  return audio\n",
    "\n",
    "def save_audio(response, count):\n",
    "  with open(f\"{summary_title}/audio/story_{count}.mp3\", \"wb\") as f:\n",
    "      f.write(response[\"AudioStream\"].read())\n",
    "\n",
    "def read_audio(file):\n",
    "  pygame.mixer.init()\n",
    "  pygame.mixer.music.load(file)\n",
    "  pygame.mixer.music.play()\n",
    "\n",
    "  while pygame.mixer.music.get_busy():\n",
    "    # Optional: add a delay to reduce CPU usage\n",
    "    time.sleep(0.1)  \n",
    "\n",
    "  return pygame.mixer.music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{summary_title}/summary.txt\", \"r\") as f:\n",
    "  story = f.read()\n",
    "count = 0\n",
    "for section in story.split('\\n\\n'):\n",
    "  audio = generate_audio(section, count)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(count):\n",
    "  section = story.split('\\n\\n')[i]\n",
    "  print(i, section)\n",
    "  media_player = read_audio(f\"{summary_title}/audio/story_{i}.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
