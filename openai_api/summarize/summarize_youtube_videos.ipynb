{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a youtube URL the following will download transcript then summarize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import youtube_dl\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import shutil\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "import re\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# video_url = 'https://www.youtube.com/watch?v=SNgoul4vyDM'\n",
    "# summary_title = \"ufo_hearing_whisper_download_transcript\"\n",
    "\n",
    "video_url = 'https://www.youtube.com/watch?v=34wA_bdG6QQ'\n",
    "summary_title = \"lex_fridman_391\"\n",
    "\n",
    "video_id = video_url.split('=')[1]\n",
    "task = \"Please provide a detailed summary of the following: \\n\"\n",
    "\n",
    "chunk_size = 2300\n",
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "models = ['gpt-3.5-turbo', 'gpt-4']\n",
    "USE = 0\n",
    "TRANSCRIBE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_from_youtube(video_url, output_path, file_name=\"audio.mp4\"):\n",
    "    try:\n",
    "        yt = YouTube(video_url)\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        audio_stream.download(output_path, filename=file_name)\n",
    "        print(\"Audio download completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "def split_audio_into_chunks(input_file, output_folder, chunk_duration=900):\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    audio_duration_ms = len(audio)\n",
    "    for start_time_ms in range(0, audio_duration_ms, chunk_duration * 1000):\n",
    "        end_time_ms = start_time_ms + (chunk_duration * 1000)\n",
    "        chunk = audio[start_time_ms:end_time_ms]\n",
    "        location = f\"{output_folder}/audio_chunks\"\n",
    "        if not os.path.exists(location):\n",
    "            os.makedirs(location)\n",
    "        output_file = f\"{output_folder}/audio_chunks/chunk_{start_time_ms//1000}.mp4\"\n",
    "        chunk.export(output_file, format=\"mp4\")\n",
    "\n",
    "\n",
    "def get_video_title(url):\n",
    "    with youtube_dl.YoutubeDL({}) as ydl:\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        return info_dict.get('title', None)\n",
    "\n",
    "\n",
    "def summarize(input, model=models[USE]):\n",
    "    global input_tokens, output_tokens\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        input_cost = 0.0015/1000\n",
    "        output_cost = 0.002/1000\n",
    "    else:\n",
    "        input_cost = 0.03/1000\n",
    "        output_cost = 0.06/1000\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": \"I am going to be providing you with chunks of text and I want you to summarize it for me. Sometimes I will also be giving you a summary of a previous chunk of text. Please only summarize the new chunk of text while also taking into account the previous summary. Also, don't ever mention the text or chunk of text or the summary in your response. Keep as much detail as possible.\"},\n",
    "          {\"role\": \"user\", \"content\": input}])\n",
    "    input_tokens += completion.usage.prompt_tokens\n",
    "    output_tokens += completion.usage.completion_tokens\n",
    "\n",
    "    cost = input_tokens*input_cost + output_tokens*output_cost\n",
    "    print(f\"Tokens thus far: {input_tokens + output_tokens} with a cost of ${round(cost, 4)}\")\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    return reply_content\n",
    "\n",
    "\n",
    "def create_directory(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "def download_transcript(video_id):\n",
    "    video_id = video_id.split('=')[-1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "    with open(f\"{summary_title}/transcript.txt\", \"w\") as file:\n",
    "        for line in transcript:\n",
    "            file.write(line['text'] + '\\n')\n",
    "\n",
    "def chunk_transcript_sentences(file_name, chunk_size, summary_title):\n",
    "    # Open and read the file\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read().replace('\\n', ' ')\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split('(?<=[.!?]) +', text)\n",
    "\n",
    "    chunks, chunk = [], []\n",
    "    current_chunk_size = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split(' ')\n",
    "        sentence_length = len(sentence_words)\n",
    "        \n",
    "        # If adding the next sentence doesn't exceed the chunk size, add it to the current chunk\n",
    "        if current_chunk_size + sentence_length <= chunk_size:\n",
    "            chunk.append(sentence)\n",
    "            current_chunk_size += sentence_length\n",
    "        else:\n",
    "            # Otherwise, finish the current chunk and start a new one\n",
    "            chunks.append(' '.join(chunk))\n",
    "            chunk = [sentence]\n",
    "            current_chunk_size = sentence_length\n",
    "\n",
    "    # Add the last chunk if it's non-empty\n",
    "    if chunk:\n",
    "        chunks.append(' '.join(chunk))\n",
    "\n",
    "    create_directory(f\"{summary_title}/chunks\")\n",
    "\n",
    "    # Write each chunk to a file\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(f'{summary_title}/chunks/chunk{i}.txt', 'w') as file:\n",
    "            file.write(chunk)\n",
    "\n",
    "def chunk_transcript(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read().replace('\\n', ' ')\n",
    "    words = text.split(' ')\n",
    "    chunks = [words[i:i + chunk_size]\n",
    "              for i in range(0, len(words), chunk_size)]\n",
    "    create_directory(f\"{summary_title}/chunks\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(f'{summary_title}/chunks/chunk{i}.txt', 'w') as file:\n",
    "            file.write(' '.join(chunk))\n",
    "\n",
    "\n",
    "def get_sorted_files_by_date(directory):\n",
    "    file_list = os.listdir(directory)\n",
    "    files_with_mtime = [(file, os.path.getmtime(\n",
    "        os.path.join(directory, file))) for file in file_list]\n",
    "    sorted_files = sorted(files_with_mtime, key=lambda x: x[1])\n",
    "    sorted_filenames = [file[0] for file in sorted_files]\n",
    "    return sorted_filenames\n",
    "\n",
    "\n",
    "def read_text_from_files(directory_path):\n",
    "    text_array = []\n",
    "    files = get_sorted_files_by_date(directory_path)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                text_array.append(file.read())\n",
    "    return text_array\n",
    "\n",
    "\n",
    "def read_and_join_text_from_files(directory_path):\n",
    "    joined_text = \"\"\n",
    "    files = get_sorted_files_by_date(directory_path)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                joined_text += file.read() + \"\\n\"\n",
    "    return joined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(summary_title):\n",
    "  shutil.rmtree(summary_title)\n",
    "create_directory(summary_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download audio then transcribe using openai whisper api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSCRIBE:\n",
    "    download_audio_from_youtube(video_url, summary_title)\n",
    "    split_audio_into_chunks(summary_title+\"/audio.mp4\",\n",
    "                            summary_title, chunk_duration=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSCRIBE:\n",
    "    files = get_sorted_files_by_date(summary_title+\"/audio_chunks\")\n",
    "    print(f\"Chunks to transcribe: {files}\")\n",
    "    if os.path.exists(f\"{summary_title}/transcript.txt\"):\n",
    "        os.remove(f\"{summary_title}/transcript.txt\")\n",
    "    for file in files:\n",
    "        print(f\"Transcribing {file}\")\n",
    "        file = open(summary_title + \"/audio_chunks/\" + file, \"rb\")\n",
    "        transcript = \"\\n\" + openai.Audio.transcribe(\"whisper-1\", file).text\n",
    "        with open(f\"{summary_title}/transcript.txt\", \"a\") as f:\n",
    "            f.write(transcript)\n",
    "else:\n",
    "    download_transcript(video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(summary_title+\"/chunks\"):\n",
    "    shutil.rmtree(summary_title+\"/chunks\")\n",
    "create_directory(summary_title+\"/chunks\")\n",
    "# chunk_transcript(f'{summary_title}/transcript.txt', chunk_size, summary_title)\n",
    "chunk_transcript(f'{summary_title}/transcript.txt')\n",
    "data = read_text_from_files(f\"{summary_title}/chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(summary_title+\"/summaries\"):\n",
    "    shutil.rmtree(summary_title+\"/summaries\")\n",
    "create_directory(f\"{summary_title}/summaries\")\n",
    "\n",
    "if os.path.exists(summary_title+\"/instructions\"):\n",
    "    shutil.rmtree(summary_title+\"/instructions\")\n",
    "create_directory(f\"{summary_title}/instructions\")\n",
    "\n",
    "print(f\"Summarizing {len(data)} articles\")\n",
    "multiple_summaries = len(data) > 1\n",
    "for i in range(len(data)):\n",
    "    previous_summary = \"\"\n",
    "    if i > 0:\n",
    "        with open(f\"{summary_title}/summaries/summary{i-1}.txt\", \"r\") as f:\n",
    "            previous_summary = \"Please provide a detailed (keep as much detail as possible) summary while keeping the following context in mind: \\n\" + f.read().replace('\\n', ' ') + \"\\n\\n\"\n",
    "    else:\n",
    "        previous_summary = \"Please provide a detailed summary of the following while keeping as much details in as possible: \\n\"\n",
    "    instruction = previous_summary + data[i]\n",
    "    with open(f\"{summary_title}/instructions/instruction_{i}.txt\", \"w\") as file:\n",
    "        file.write(instruction)\n",
    "    print(f\"Summarizing article {i} with {len(instruction.split(' '))} words\")\n",
    "    response = summarize(instruction)\n",
    "    with open(f\"{summary_title}/summaries/summary{i}.txt\", \"w\") as f:\n",
    "        f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join summaries together then summarize them altogether using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = f'{summary_title}/summaries'\n",
    "joined_text_variable = read_and_join_text_from_files(directory_path)\n",
    "files = get_sorted_files_by_date(directory_path)\n",
    "multiple_summaries = len(files) > 1\n",
    "with open(f'{summary_title}/summaries/joined_text.txt', 'w') as file:\n",
    "    file.write(joined_text_variable)\n",
    "if multiple_summaries:\n",
    "    print(f\"Summarizing joined summaries with {len(joined_text_variable.split(' '))} words\")\n",
    "\n",
    "    instruction = \"Make the following summaries flow as one long and detailed article: \\n\" + joined_text_variable.rstrip()\n",
    "    with open(f\"{summary_title}/instructions/instruction.txt\", \"w\") as f:\n",
    "        f.write(instruction)\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": instruction}])\n",
    "    sum = completion.choices[0].message.content\n",
    "else:\n",
    "    sum = joined_text_variable\n",
    "with open(f\"{summary_title}/summary.txt\", \"w\") as f:\n",
    "    f.write(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "voice_id = \"Matthew\"\n",
    "output_format = \"mp3\"\n",
    "import pygame\n",
    "\n",
    "if os.path.exists(summary_title+\"/audio\"):\n",
    "    shutil.rmtree(summary_title+\"/audio\")\n",
    "create_directory(f\"{summary_title}/audio\")\n",
    "\n",
    "# Create an Amazon Polly client\n",
    "polly_client = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"polly_access_key_id\"),\n",
    "    aws_secret_access_key=os.getenv(\"polly_secret_key\"),\n",
    "    region_name='ca-central-1').client('polly')\n",
    "\n",
    "def generate_audio(input, count):\n",
    "  start_time = time.time()\n",
    "  audio = polly_client.synthesize_speech(\n",
    "      Text=input,\n",
    "      VoiceId=voice_id,\n",
    "      OutputFormat=output_format,\n",
    "      Engine=\"neural\"\n",
    "      )\n",
    "  save_audio(audio, count)\n",
    "  return audio\n",
    "\n",
    "def save_audio(response, count):\n",
    "  with open(f\"{summary_title}/audio/story_{count}.mp3\", \"wb\") as f:\n",
    "      f.write(response[\"AudioStream\"].read())\n",
    "\n",
    "def read_audio(file):\n",
    "  pygame.mixer.init()\n",
    "  pygame.mixer.music.load(file)\n",
    "  pygame.mixer.music.play()\n",
    "\n",
    "  while pygame.mixer.music.get_busy():\n",
    "    # Optional: add a delay to reduce CPU usage\n",
    "    time.sleep(0.1)  \n",
    "\n",
    "  return pygame.mixer.music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{summary_title}/summary.txt\", \"r\") as f:\n",
    "  story = f.read()\n",
    "count = 0\n",
    "for section in story.split('\\n\\n'):\n",
    "  audio = generate_audio(section, count)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(count):\n",
    "  section = story.split('\\n\\n')[i]\n",
    "  print(i, section)\n",
    "  media_player = read_audio(f\"{summary_title}/audio/story_{i}.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
