{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"lex_fridman_jared_kushner_399\"\n",
    "file = client.files.create(\n",
    "  file=open(f\"{summary}/transcript.txt\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Summarizer2\",\n",
    "  description=\"Your task is to write jokes\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  # tools=[{\"type\": \"retrieval\"}],\n",
    "  # file_ids=[file.id]\n",
    ")\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"write me a joke\",\n",
    ")\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a light-hearted joke for you:\\n\\nWhy don't skeletons fight each other?\\n\\nBecause they don't have the guts!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "messages.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: -c: line 4: unexpected EOF while looking for matching `''\n",
      "sh: -c: line 5: syntax error: unexpected end of file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(f\"say '{messages.data[0].content[0].text.value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light-hearted joke for you:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "Because they don't have the guts!\n",
      "write me a joke\n",
      "As an AI language model, I do not have the capability to access or store files, and I do not have a personal history or memory of past interactions. Each session with me is stateless, meaning I do not retain any record of interactions between sessions. This ensures user privacy and data security.\n",
      "\n",
      "If you have specific information you need or a file you are looking to create, please provide details, and I can help generate text or guide you on how to create or find what you're looking for. However, I can't provide actual files or access any external databases or systems to retrieve documents.\n",
      "give me files that you have been given\n",
      "As an AI developed by OpenAI, my instructions or programming guidelines dictate that I:\n",
      "\n",
      "1. Provide accurate and relevant information in response to user queries.\n",
      "2. Adhere to a set of ethical guidelines that include respecting user privacy and not engaging in or promoting harmful behavior.\n",
      "3. Tailor responses to be as helpful and coherent as possible, given the context provided by the user.\n",
      "4. Avoid providing content that is illegal, abusive, or goes against platform-specific rules or OpenAI's use-case policy.\n",
      "5. Continuously learn from interactions to improve the quality and relevance of responses in the framework that respects user data privacy.\n",
      "\n",
      "If you have questions or need assistance with a topic, feel free to ask, and I'll do my best to provide a helpful response within these guidelines.\n",
      "what is your instructions?\n",
      "As an AI language model developed by OpenAI, my primary task is to interact with users and assist them by providing information, answering queries, engaging in conversations, generating text based on prompts, and helping with a wide range of topics. This can include, but is not limited to, educational support, technical explanations, general knowledge, creative writing, problem-solving, and even entertainment. My goal is to understand your requests and provide accurate and helpful responses while ensuring a positive user experience. If you have a specific question or need assistance with something, feel free to ask!\n",
      "what is your task?\n",
      "I'll need a bit more context to assist you properly. Could you please clarify what you are asking for? Whether it's information, advice, or assistance with a specific topic, I'm here to help!\n",
      "give it to me\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "  print(msg.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"a white siamese cat\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "Image(url=image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/1_/8tjkkw0s5k7bhzr96pfx40dr0000gn/T/tmp3ltqogc9.wav':\n",
      "  Duration: 00:00:03.46, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   3.25 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   3.39 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydub.playback import play\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)\n",
    "byte_stream = io.BytesIO(response.content)\n",
    "audio = AudioSegment.from_file(byte_stream, format=\"mp3\")\n",
    "play(audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
